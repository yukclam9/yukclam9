1
00:00:00 --> 00:00:00



2
00:00:00 --> 00:00:02
The following content is
provided under a Creative

3
00:00:02 --> 00:00:03
Commons license.


4
00:00:03 --> 00:00:06
Your support will help MIT
OpenCourseWare continue to

5
00:00:06 --> 00:00:10
offer high quality educational
resources for free.

6
00:00:10 --> 00:00:13
To make a donation or view
additional materials from

7
00:00:13 --> 00:00:17
hundreds of MIT courses,
visit MIT OpenCourseWare

8
00:00:17 --> 00:00:21
at ocw.mit.edu.


9
00:00:21 --> 00:00:23
PROFESSOR: I want to take a few
minutes at the start of today's

10
00:00:23 --> 00:00:27
lecture to wrap up a few more
things about debugging.

11
00:00:27 --> 00:00:33
And then I'll move on
to the main event.

12
00:00:33 --> 00:00:34
Just a few small points.


13
00:00:34 --> 00:00:38
First of all, keep in mind
that the bug is probably

14
00:00:38 --> 00:00:40
not where you think it is.


15
00:00:40 --> 00:00:45
Because if a bug were there,
you'd have already found it.

16
00:00:45 --> 00:00:49
There are some simple things
that you should always look at

17
00:00:49 --> 00:00:54
when you're looking for bugs.


18
00:00:54 --> 00:00:59
Reversed order of arguments.


19
00:00:59 --> 00:01:03
You might have a function that
takes to floats and you just

20
00:01:03 --> 00:01:06
passed them in the wrong order.


21
00:01:06 --> 00:01:09
You may have noticed that when
Professor Grimson and I used

22
00:01:09 --> 00:01:12
examples in class, we were
pretty careful how we

23
00:01:12 --> 00:01:14
name our parameters.


24
00:01:14 --> 00:01:17
And I often end up using
the same names for the

25
00:01:17 --> 00:01:19
actuals and the formals.


26
00:01:19 --> 00:01:22
And this just helps me not
get confused about what

27
00:01:22 --> 00:01:25
order to do things in.


28
00:01:25 --> 00:01:30
Spelling.


29
00:01:30 --> 00:01:32
These are just dumb little
things to look for.

30
00:01:32 --> 00:01:34
Did you spell all the
identifiers the way

31
00:01:34 --> 00:01:35
you think you did.


32
00:01:35 --> 00:01:38
The problem is, when you
read code you see what

33
00:01:38 --> 00:01:41
you expect to see.


34
00:01:41 --> 00:01:43
And if you've typed in l when
you should've typed a 1, or a

35
00:01:43 --> 00:01:48
1 when you should've typed an
l, you're likely to miss it.

36
00:01:48 --> 00:01:50
If you've made a mistake
with upper and lower case.

37
00:01:50 --> 00:01:52
Things like that.


38
00:01:52 --> 00:01:57
So just be very careful
looking at that.

39
00:01:57 --> 00:02:04
Initialization.


40
00:02:04 --> 00:02:09
A very common bug is to
initialize a variable.

41
00:02:09 --> 00:02:12
Go through a loop, and then
forget to reinitialize

42
00:02:12 --> 00:02:15
it when it needs to be
reinitialized again.

43
00:02:15 --> 00:02:17
So it's initialized outside
the loop when it should be

44
00:02:17 --> 00:02:20
initialized inside the loop.


45
00:02:20 --> 00:02:22
Or conversely, inside
the loop when it should

46
00:02:22 --> 00:02:24
be outside the loop.


47
00:02:24 --> 00:02:27
So look carefully at
when variables are

48
00:02:27 --> 00:02:35
being initialized.


49
00:02:35 --> 00:02:43
Object versus value equality.


50
00:02:43 --> 00:02:47
Particularly when you use
double equals, are you asking

51
00:02:47 --> 00:02:51
whether you've got the same
object or the same value?

52
00:02:51 --> 00:02:54
They mean very different
things, as we have seen.

53
00:02:54 --> 00:02:58
Keep track of that.


54
00:02:58 --> 00:03:05
Related to that is aliasing.


55
00:03:05 --> 00:03:08
And you'll see that, by the
way, on the problem set that

56
00:03:08 --> 00:03:10
we're posting tomorrow.


57
00:03:10 --> 00:03:13
Where we're going to ask you to
just look at some code, that

58
00:03:13 --> 00:03:17
there's some issues there with
the fact that you alias

59
00:03:17 --> 00:03:20
things, maybe on purpose,
maybe on accident.

60
00:03:20 --> 00:03:24
And by that I mean two
different ways to get to the

61
00:03:24 --> 00:03:27
same value, the same object.


62
00:03:27 --> 00:03:33
Frequently that introduces
bugs into the program.

63
00:03:33 --> 00:03:42
A particular instance of that
is deep versus shallow copy.

64
00:03:42 --> 00:03:46
When you decide to make a copy
of something like a list, you

65
00:03:46 --> 00:03:50
have to think hard about are
you only copying the top level

66
00:03:50 --> 00:03:55
of the list, but if it's, say,
a list that contains a list,

67
00:03:55 --> 00:04:00
are you also getting a new copy
of everything it contains?

68
00:04:00 --> 00:04:02
It doesn't matter if it's a
list of integers or a list of

69
00:04:02 --> 00:04:06
strings or a list of tuples,
but it matters a lot if

70
00:04:06 --> 00:04:08
it's a list of lists.


71
00:04:08 --> 00:04:11
Or a list of anything
that could be mutable.

72
00:04:11 --> 00:04:14
So when you copy, what
are you getting?

73
00:04:14 --> 00:04:17
When you copy a
dictionary, for example.

74
00:04:17 --> 00:04:20
Think through all of that.


75
00:04:20 --> 00:04:23
And again, a related problem
that people run into

76
00:04:23 --> 00:04:29
is side-effects.


77
00:04:29 --> 00:04:33
You call a function and it
returns a value, but maybe it,

78
00:04:33 --> 00:04:37
on purpose or on accident,
modifies one of the

79
00:04:37 --> 00:04:40
actual parameters.


80
00:04:40 --> 00:04:45
So you could each make
a list of things.

81
00:04:45 --> 00:04:50
Every experienced programmer
over time develops a

82
00:04:50 --> 00:04:54
personal model of the
mistakes they make.

83
00:04:54 --> 00:04:57
I know the kinds of
things I get wrong.

84
00:04:57 --> 00:04:59
And so when I'm looking for
a bug, I always say, oh,

85
00:04:59 --> 00:05:04
have you done this dumb
thing you always do.

86
00:05:04 --> 00:05:06
So be a little bit
introspective.

87
00:05:06 --> 00:05:09
Keep track of the
mistakes you make.

88
00:05:09 --> 00:05:12
And if your program doesn't
work, that should be

89
00:05:12 --> 00:05:15
your first guess.


90
00:05:15 --> 00:05:18
Couple of other hints.


91
00:05:18 --> 00:05:30
Keep a record of
what you've tried.

92
00:05:30 --> 00:05:33
People will look at things and
they'll come in and that'll

93
00:05:33 --> 00:05:37
talk to a TA, and the TA
will say, did you try this?

94
00:05:37 --> 00:05:40
And the person will
say, I don't know.

95
00:05:40 --> 00:05:42
That leads you to end up
doing the same thing

96
00:05:42 --> 00:05:44
over and over again.


97
00:05:44 --> 00:05:47
This gets back to my main
theme of Tuesday, which

98
00:05:47 --> 00:05:49
is be systematic.


99
00:05:49 --> 00:05:51
Know what you've already
tried, don't waste your

100
00:05:51 --> 00:05:57
time trying it again.


101
00:05:57 --> 00:06:08
Think about reconsidering
your assumptions.

102
00:06:08 --> 00:06:13
A huge one is, are you actually
running the code you're

103
00:06:13 --> 00:06:16
looking at in your editor.


104
00:06:16 --> 00:06:21
This is a mistake I make
all the time in Python.

105
00:06:21 --> 00:06:25
I sit there in idle,
and I edit some code.

106
00:06:25 --> 00:06:31
I then click on the shell,
rather than hitting F5, try and

107
00:06:31 --> 00:06:35
run it and say, it's not doing
what I thought I should do.

108
00:06:35 --> 00:06:37
And I'll sit there staring at
the output, staring at the

109
00:06:37 --> 00:06:41
code, not realizing that that
output was not produced

110
00:06:41 --> 00:06:45
by that code.


111
00:06:45 --> 00:06:48
It's a mistake I've
learned that I make.

112
00:06:48 --> 00:06:52
It's an easy one to
make in Python.

113
00:06:52 --> 00:06:54
Lots of assumptions like that.


114
00:06:54 --> 00:06:58
You thought you knew what
the built-in function sort

115
00:06:58 --> 00:07:00
did, method sort did.


116
00:07:00 --> 00:07:02
Well, does it do what
you think it does?

117
00:07:02 --> 00:07:05
Does append do what
you think it does?

118
00:07:05 --> 00:07:07
Go back and say, alright,
I've obviously, some

119
00:07:07 --> 00:07:13
assumption is not right.


120
00:07:13 --> 00:07:20
When you're debugging somebody
else's code, debug the

121
00:07:20 --> 00:07:27
code, not the comments.


122
00:07:27 --> 00:07:30
I've often made the mistake of
believing the comments somebody

123
00:07:30 --> 00:07:34
wrote in your code about
what some function does.

124
00:07:34 --> 00:07:36
Sometimes it's good
to believe it.

125
00:07:36 --> 00:07:41
But sometimes you
have to read it.

126
00:07:41 --> 00:07:43
Important thing.


127
00:07:43 --> 00:07:49
When it gets really
tough, get help.

128
00:07:49 --> 00:07:52
Swallow your pride.


129
00:07:52 --> 00:07:56
Any one of my graduate students
will tell you that from time to

130
00:07:56 --> 00:08:00
time I walk into their office
and say, do you have a minute?

131
00:08:00 --> 00:08:04
And if they foolishly say yes,
I drag them back to my office

132
00:08:04 --> 00:08:10
and say I'm stuck on this
bug, what am I doing wrong?

133
00:08:10 --> 00:08:13
And it's amazing what --
well, a, they're smarter

134
00:08:13 --> 00:08:15
than I am which helps.


135
00:08:15 --> 00:08:17
But even if they weren't
smarter than I am, just

136
00:08:17 --> 00:08:20
a fresh set of eyes.


137
00:08:20 --> 00:08:22
I've read through the same
thing twenty times and I've

138
00:08:22 --> 00:08:24
missed something obvious.


139
00:08:24 --> 00:08:27
Someone who's never seen it
before looks at and says, did

140
00:08:27 --> 00:08:31
you really mean to do this?


141
00:08:31 --> 00:08:35
Are you sure you didn't want
to do for i in range of list,

142
00:08:35 --> 00:08:38
rather than for i in list?


143
00:08:38 --> 00:08:41
That sort of thing.


144
00:08:41 --> 00:08:45
Makes a big difference to
just get that set of eyes.

145
00:08:45 --> 00:08:52
And in particular, try and
explain to somebody else what

146
00:08:52 --> 00:08:54
you think the program is doing.


147
00:08:54 --> 00:08:57
So I'll sit there with the
student and I'll say, I'm going

148
00:08:57 --> 00:09:00
to try and explain to you why
what I think this

149
00:09:00 --> 00:09:02
program is doing.


150
00:09:02 --> 00:09:07
And probably 80% of the time,
halfway through my explanation,

151
00:09:07 --> 00:09:10
I say, oh, never mind.


152
00:09:10 --> 00:09:11
I'm embarrassed.


153
00:09:11 --> 00:09:12
And I send them away.


154
00:09:12 --> 00:09:15
Because just the act of
explaining it to him or her

155
00:09:15 --> 00:09:17
has helped me understand it.


156
00:09:17 --> 00:09:21
So when you're really
stuck, just get somebody.

157
00:09:21 --> 00:09:24
And try and explain to them
why you think your program

158
00:09:24 --> 00:09:28
is doing what it's doing.


159
00:09:28 --> 00:09:29
Another good thing to
do when you're really

160
00:09:29 --> 00:09:36
stuck is walk away.


161
00:09:36 --> 00:09:37
Take a break.


162
00:09:37 --> 00:09:41
Come back and look at it with
fresh eyes of your own.

163
00:09:41 --> 00:09:45
Effectively, what you're doing
here is perhaps trading

164
00:09:45 --> 00:09:49
latency for efficiency.


165
00:09:49 --> 00:09:54
It may, if you go back, come
back and two hours later, maybe

166
00:09:54 --> 00:09:57
you'll, it'll take you at least
two hours to have found the

167
00:09:57 --> 00:10:00
bugs, because you've been
away for two hours.

168
00:10:00 --> 00:10:02
And maybe if you'd stayed there
and worked really hard you'd

169
00:10:02 --> 00:10:05
have found it an hour and
fifty eight minutes.

170
00:10:05 --> 00:10:07
But is it really worth
the two minutes?

171
00:10:07 --> 00:10:09
This is another reason,
by the way, to start it

172
00:10:09 --> 00:10:11
long before it's due.


173
00:10:11 --> 00:10:15
That you actually have the
leisure to walk away.

174
00:10:15 --> 00:10:16
All right.


175
00:10:16 --> 00:10:18
What do you do when
you've found the bug

176
00:10:18 --> 00:10:22
and you need to fix it?


177
00:10:22 --> 00:10:30
Remember the old saw,
haste makes waste.

178
00:10:30 --> 00:10:36
I don't know this but I'll bet
Benjamin Franklin said this.

179
00:10:36 --> 00:10:38
Don't rush into anything.


180
00:10:38 --> 00:10:42
Think about the fix, don't make
the first change that comes

181
00:10:42 --> 00:10:45
to mind and see if it works.


182
00:10:45 --> 00:10:49
Ask yourself, will it fix all
of the symptoms you've seen?

183
00:10:49 --> 00:10:52
Or if not, are the symptoms
independent, will at

184
00:10:52 --> 00:10:54
least fix some of them?


185
00:10:54 --> 00:10:59
What are the ramifications
of the proposed change.

186
00:10:59 --> 00:11:03
Will it break other things?


187
00:11:03 --> 00:11:03
That's a big issue.


188
00:11:03 --> 00:11:06
You can fix one thing, you
break something else.

189
00:11:06 --> 00:11:10
So think through what
this change might break.

190
00:11:10 --> 00:11:15
Does it allow you to
tidy up other things?

191
00:11:15 --> 00:11:23
This is important, I
think, that code should

192
00:11:23 --> 00:11:31
not always grow.


193
00:11:31 --> 00:11:36
We all have a tendency to
fix code by adding code.

194
00:11:36 --> 00:11:40
And the program just gets
bigger and bigger and bigger.

195
00:11:40 --> 00:11:45
The more code you have, the
harder it is to get it right.

196
00:11:45 --> 00:11:48
So, sometimes, what you need
to, so you just pull back.

197
00:11:48 --> 00:11:53
And say, well, let me
just tidy things up.

198
00:11:53 --> 00:11:55
That, by the way, is also
a good debugging tool.

199
00:11:55 --> 00:11:58
Sometimes when I'm really
stuck, I say, alright let me

200
00:11:58 --> 00:11:59
stop looking for the bug.


201
00:11:59 --> 00:12:01
Let me just clean up
the code a little bit.

202
00:12:01 --> 00:12:04
Make my program prettier.


203
00:12:04 --> 00:12:07
And in the process of tidying
it up and making it prettier,

204
00:12:07 --> 00:12:10
I'll often by accident
find the bug.

205
00:12:10 --> 00:12:14
So it's a good
trick to remember.

206
00:12:14 --> 00:12:26
Finally, and this is very
important, make sure

207
00:12:26 --> 00:12:31
that you can revert.


208
00:12:31 --> 00:12:37
There's nothing more
frustrating then spending four

209
00:12:37 --> 00:12:41
hours debugging, and realizing
at the end of four hours your

210
00:12:41 --> 00:12:44
program is worse than it
was when you started.

211
00:12:44 --> 00:12:49
And you can't get back to where
it was when you started.

212
00:12:49 --> 00:12:54
So if you look at one of my
directories, you'll find

213
00:12:54 --> 00:13:02
that I've been pretty anal
about saving old versions.

214
00:13:02 --> 00:13:06
I can always pretty much get
back to some place I've been.

215
00:13:06 --> 00:13:09
So if I've made a set of
changes and I realize I've

216
00:13:09 --> 00:13:12
broken something that used to
work, I can find a version of

217
00:13:12 --> 00:13:16
the code in which it used to
work, and figure out what

218
00:13:16 --> 00:13:18
was going on there.


219
00:13:18 --> 00:13:22
Disk space is cheap.


220
00:13:22 --> 00:13:25
Don't hesitate to save
your old versions.

221
00:13:25 --> 00:13:28
It's a good thing.


222
00:13:28 --> 00:13:33
Alright, that's the end of
my, maybe sermon is the

223
00:13:33 --> 00:13:34
right word on debugging.


224
00:13:34 --> 00:13:36
Polemic, I don't know.


225
00:13:36 --> 00:13:38
I hope it will be helpful.


226
00:13:38 --> 00:13:41
And I hope you'll remember some
of these things as you try and

227
00:13:41 --> 00:13:44
get your programs to work.


228
00:13:44 --> 00:13:47
I now want to get
back to algorithms.

229
00:13:47 --> 00:13:49
And where we've sort of been
for a while, and where we

230
00:13:49 --> 00:13:52
will stay for a while.


231
00:13:52 --> 00:13:56
More fundamentally, I want to
get back to what I think of as

232
00:13:56 --> 00:14:03
the main theme of 6.00, which
is taking a problem and finding

233
00:14:03 --> 00:14:08
some way to formulate the
problem so that we can use

234
00:14:08 --> 00:14:13
computing to help
us get an answer.

235
00:14:13 --> 00:14:17
And in particular, we're going
to spend the next few lectures

236
00:14:17 --> 00:14:32
looking at a class of problems
known as optimization problems.

237
00:14:32 --> 00:14:38
In general, every optimization
problem is the same.

238
00:14:38 --> 00:14:41
It has two parts.


239
00:14:41 --> 00:14:50
Some function that you're
either attempting to maximize

240
00:14:50 --> 00:14:57
or minimize the value of.


241
00:14:57 --> 00:15:00
And these are duals.


242
00:15:00 --> 00:15:14
And some set of constraints
that must be honored.

243
00:15:14 --> 00:15:17
Possibly an empty
set of constraints.

244
00:15:17 --> 00:15:22
So what are some of the classic
optimization problems?

245
00:15:22 --> 00:15:26
Well one of the most
well-known is the so-called

246
00:15:26 --> 00:15:33
shortest path problem.


247
00:15:33 --> 00:15:35
Probably almost every
one of you has used a

248
00:15:35 --> 00:15:37
shortest path algorithm.


249
00:15:37 --> 00:15:41
For example, if you go to
Mapquest, or Google Maps

250
00:15:41 --> 00:15:45
and ask how do I get
from here to there.

251
00:15:45 --> 00:15:48
You give it the function,
probably in this case to

252
00:15:48 --> 00:15:51
minimize, and it gives you
a choice of functions.

253
00:15:51 --> 00:15:56
Minimize time,
minimize distance.

254
00:15:56 --> 00:15:58
And maybe you give it
a set of constraints.

255
00:15:58 --> 00:16:01
I don't want to
drive on highways.

256
00:16:01 --> 00:16:04
And it tries to find the
shortest way, subject to those

257
00:16:04 --> 00:16:09
constraints, to get from
Point A to Point B.

258
00:16:09 --> 00:16:11
And there are many, many
other instances of

259
00:16:11 --> 00:16:13
this kind of thing.


260
00:16:13 --> 00:16:17
And tomorrow it's recitation,
we'll spend quite a bit of time

261
00:16:17 --> 00:16:20
on shortest path problems.


262
00:16:20 --> 00:16:25
Another classic optimization
problem is the

263
00:16:25 --> 00:16:27
traveling salesman.


264
00:16:27 --> 00:16:34
Actually, I should probably, be
modern, call it the traveling

265
00:16:34 --> 00:16:44
salesperson, the traveling
salesperson problem.

266
00:16:44 --> 00:16:49
So the problem here, roughly,
is given, a number of cities,

267
00:16:49 --> 00:16:53
and say the cost of traveling
from city to city by airplane,

268
00:16:53 --> 00:16:59
what's the least cost round
trip that you can find?

269
00:16:59 --> 00:17:01
So you start at one place,
you have to go to a

270
00:17:01 --> 00:17:02
number of other places.


271
00:17:02 --> 00:17:05
End up where you started.


272
00:17:05 --> 00:17:09
It's not quite the same as the
shortest path, and figure out

273
00:17:09 --> 00:17:11
the way to do that that
involves spending

274
00:17:11 --> 00:17:12
the least money.


275
00:17:12 --> 00:17:19
Or the least time,
or something else.

276
00:17:19 --> 00:17:27
What are some of the other
classic optimization problems?

277
00:17:27 --> 00:17:36
There's bin packing.


278
00:17:36 --> 00:17:40
Filling up some container
with objects of varying

279
00:17:40 --> 00:17:43
size and, perhaps, shape.


280
00:17:43 --> 00:17:45
So you've got the trunk of
your car and you've got

281
00:17:45 --> 00:17:47
a bunch of luggage.


282
00:17:47 --> 00:17:49
More luggage than can
actually fit in.

283
00:17:49 --> 00:17:52
And you're trying to figure out
what order to put things in.

284
00:17:52 --> 00:17:54
And which ones you can put in.


285
00:17:54 --> 00:17:57
How to fill up that bin.


286
00:17:57 --> 00:17:59
Very important in shipping.


287
00:17:59 --> 00:18:01
People use bin packing
algorithms to figure out,

288
00:18:01 --> 00:18:04
for example, how to load
up container ships.

289
00:18:04 --> 00:18:05
Things of that nature.


290
00:18:05 --> 00:18:11
Moving vans, all sorts of
things of that nature.

291
00:18:11 --> 00:18:15
In biology and in natural
language processing and many

292
00:18:15 --> 00:18:23
other things, we see a lot of
sequence alignment problems.

293
00:18:23 --> 00:18:31
For example, aligning DNA
sequences, or RNA sequences.

294
00:18:31 --> 00:18:36
And, one we'll spend a fair
amount of time on today

295
00:18:36 --> 00:18:43
and Tuesday is the
knapsack problem.

296
00:18:43 --> 00:18:47
In the old days people used
to call backpacks knapsacks.

297
00:18:47 --> 00:18:52
So we old folks sometimes even
still make that mistake.

298
00:18:52 --> 00:18:55
And the problem there is,
you've got a bunch of things.

299
00:18:55 --> 00:18:58
More than will fit into the
knapsack, and you're trying to

300
00:18:58 --> 00:19:01
figure out which things to take
and which things to leave.

301
00:19:01 --> 00:19:03
As you plan your hiking trip.


302
00:19:03 --> 00:19:05
How much water should you take.


303
00:19:05 --> 00:19:06
How many blankets?


304
00:19:06 --> 00:19:08
How much food?


305
00:19:08 --> 00:19:12
And you're trying to optimize
the value of the objects you

306
00:19:12 --> 00:19:15
can take subject to the
constraint that the backpack

307
00:19:15 --> 00:19:20
is of finite size.


308
00:19:20 --> 00:19:24
Now, why am I telling
you all of this at

309
00:19:24 --> 00:19:27
this lightning speed?


310
00:19:27 --> 00:19:31
It's because I want you
to think about it, going

311
00:19:31 --> 00:19:39
forward, about the issue
of problem reduction.

312
00:19:39 --> 00:19:47
We'll come back to this.


313
00:19:47 --> 00:19:51
What this basically means is,
you're given some problem to

314
00:19:51 --> 00:19:54
solve, that you've
never seen before.

315
00:19:54 --> 00:20:00
And the first thing you do is
ask is it an instance of some

316
00:20:00 --> 00:20:06
problem that other people
have already solved?

317
00:20:06 --> 00:20:10
So when the folks at Mapquest
sat down to do their program, I

318
00:20:10 --> 00:20:15
guarantee you somebody opened
an algorithms book and said,

319
00:20:15 --> 00:20:20
what have other people done to
solve shortest path problems?

320
00:20:20 --> 00:20:23
I'll rely on fifty years of
clever people rather than

321
00:20:23 --> 00:20:26
trying to invent my own.


322
00:20:26 --> 00:20:29
And so frequently what we try
and do is, we take a new

323
00:20:29 --> 00:20:34
problem and map it onto an old
problem so that we can

324
00:20:34 --> 00:20:37
use an old solution.


325
00:20:37 --> 00:20:41
In order to be able to do that,
it's nice to have in our heads

326
00:20:41 --> 00:20:46
an inventory of previously
solved problems.

327
00:20:46 --> 00:20:50
To which we can reduce
the current problem.

328
00:20:50 --> 00:20:54
So as we go through this
semester, we'll look at,

329
00:20:54 --> 00:20:57
briefly or not so briefly,
different previously solved

330
00:20:57 --> 00:21:01
problems in the hope that at
some time in your future, when

331
00:21:01 --> 00:21:05
you have a problem to deal
with, you'll say, I know that's

332
00:21:05 --> 00:21:09
really like shortest path, or
really like graph coloring.

333
00:21:09 --> 00:21:14
Let me just take my problem and
turn it into that problem,

334
00:21:14 --> 00:21:18
and use an existing solution.


335
00:21:18 --> 00:21:22
So we'll start looking in
detail at one problem, and

336
00:21:22 --> 00:21:30
that's the knapsack problem.


337
00:21:30 --> 00:21:30
Let's see.


338
00:21:30 --> 00:21:31
Where do I want to start?


339
00:21:31 --> 00:21:33
Oh yes, OK.


340
00:21:33 --> 00:21:36
So far, we've been looking
at problems that have

341
00:21:36 --> 00:21:41
pretty fast solutions.


342
00:21:41 --> 00:21:46
Most optimization problems
do not have fast solutions.

343
00:21:46 --> 00:21:49
That is to say, when you're
dealing with a large set of

344
00:21:49 --> 00:21:54
things, it takes a while
to get the right answer.

345
00:21:54 --> 00:21:58
Consequently, you have
to be clever about it.

346
00:21:58 --> 00:22:00
Typically up till now, we've
looked at things that can

347
00:22:00 --> 00:22:03
be done in sublinear time.


348
00:22:03 --> 00:22:09
Or, at worst, polynomial time.


349
00:22:09 --> 00:22:12
We'll now look at a problem
that does not fall into that.

350
00:22:12 --> 00:22:15
And we'll start with what's
called the continuous

351
00:22:15 --> 00:22:22
knapsack problem.


352
00:22:22 --> 00:22:26
So here's the classic
formulation.

353
00:22:26 --> 00:22:30
Assume that you are a burglar.


354
00:22:30 --> 00:22:32
And you have a backpack
that holds, say, eight

355
00:22:32 --> 00:22:35
pounds' worth of stuff.


356
00:22:35 --> 00:22:38
And you've now broken into
a house and you're trying

357
00:22:38 --> 00:22:41
to decide what to take.


358
00:22:41 --> 00:22:44
Well, let's assume in the
continuous world, what you

359
00:22:44 --> 00:22:48
is you walk into the house
and you see something like

360
00:22:48 --> 00:22:56
four pounds of gold dust.


361
00:22:56 --> 00:23:04
And you see three pounds
of silver dust, and maybe

362
00:23:04 --> 00:23:06
ten pounds of raisins.


363
00:23:06 --> 00:23:08
And I don't actually
know the periodic table

364
00:23:08 --> 00:23:11
entry for raisins.


365
00:23:11 --> 00:23:16
So I'll have to write it out.


366
00:23:16 --> 00:23:21
Well, how would you
solve this problem?

367
00:23:21 --> 00:23:24
First, let's say,
what is the problem?

368
00:23:24 --> 00:23:27
How can we formulate it?


369
00:23:27 --> 00:23:33
Well, let's assume that what
we want to do is, we have

370
00:23:33 --> 00:23:35
something we want to optimize.


371
00:23:35 --> 00:23:41
So we're looking for a function
to maximize, in this case.

372
00:23:41 --> 00:23:44
What might that function be?


373
00:23:44 --> 00:23:51
Well, let's say it's some
number of, some amount of, the

374
00:23:51 --> 00:23:56
cost of the value of gold.


375
00:23:56 --> 00:24:00
Times however many
pounds of gold.

376
00:24:00 --> 00:24:08
Plus the cost of silver
times however many - no,

377
00:24:08 --> 00:24:10
gold, is a g, isn't it.


378
00:24:10 --> 00:24:18
Pounds of silver, plus the cost
of raisins times the number

379
00:24:18 --> 00:24:21
of pounds of raisins.


380
00:24:21 --> 00:24:24
So that's the function
I want to optimize.

381
00:24:24 --> 00:24:30
I want to maximize
that function.

382
00:24:30 --> 00:24:40
And the constraint is what?


383
00:24:40 --> 00:24:45
It's that the pounds of gold
plus the pounds of silver plus

384
00:24:45 --> 00:24:52
the pounds of raisins is
no greater than eight.

385
00:24:52 --> 00:24:54
So I've got a function to
maximize and a constraint

386
00:24:54 --> 00:24:58
that must be obeyed.


387
00:24:58 --> 00:25:01
Now, the strategy here
is pretty clear.

388
00:25:01 --> 00:25:04
As often is for the
continuous problem.

389
00:25:04 --> 00:25:06
What's the strategy?


390
00:25:06 --> 00:25:09
I pour in the gold till
I run out of gold.

391
00:25:09 --> 00:25:12
I pour in the silver until
I run out of silver.

392
00:25:12 --> 00:25:16
And then I take as many raisins
as will fit in and I leave.

393
00:25:16 --> 00:25:18
Right?


394
00:25:18 --> 00:25:20
I hope almost every one of
you could figure out that

395
00:25:20 --> 00:25:22
was the right strategy.


396
00:25:22 --> 00:25:29
If not, you're not well
suited to a life of crime.

397
00:25:29 --> 00:25:43
What I just described is an
instance of a greedy algorithm.

398
00:25:43 --> 00:25:49
In a greedy algorithm, at every
step you do what maximizes

399
00:25:49 --> 00:25:52
your value at that step.


400
00:25:52 --> 00:25:55
So there's no planning ahead.


401
00:25:55 --> 00:25:57
You just do what's ever best.


402
00:25:57 --> 00:25:59
It's like when someone
gets their food and they

403
00:25:59 --> 00:26:01
start by eating dessert.


404
00:26:01 --> 00:26:03
Just to make sure they
get to the best part

405
00:26:03 --> 00:26:07
before they're full.


406
00:26:07 --> 00:26:12
In this case, a greedy
algorithm actually gives us

407
00:26:12 --> 00:26:18
the best possible solution.


408
00:26:18 --> 00:26:21
That's not always so.


409
00:26:21 --> 00:26:25
Now, you've actually all
implemented a greedy algorithm.

410
00:26:25 --> 00:26:28
Or are in the process thereof.


411
00:26:28 --> 00:26:31
Where have we implemented a
greedy algorithm, or have been

412
00:26:31 --> 00:26:36
asked to do a greedy algorithm?


413
00:26:36 --> 00:26:37
Well, there are not that many
things you guys have been

414
00:26:37 --> 00:26:41
working on this semester.


415
00:26:41 --> 00:26:41
Yeah?


416
00:26:41 --> 00:26:48
STUDENT: [INAUDIBLE]


417
00:26:48 --> 00:26:50
PROFESSOR: Exactly right.


418
00:26:50 --> 00:27:01
So what you were doing there,
it was a really good throw.

419
00:27:01 --> 00:27:03
But it was a really
good answer you gave.

420
00:27:03 --> 00:27:09
So I'll forgive you
the bad hands.

421
00:27:09 --> 00:27:11
You were asked to choose
the word that gave you

422
00:27:11 --> 00:27:14
the maximum value.


423
00:27:14 --> 00:27:20
And then do it again with
whatever letters you had left.

424
00:27:20 --> 00:27:23
Was that guaranteed to win?


425
00:27:23 --> 00:27:27
To give you the best
possible scores?

426
00:27:27 --> 00:27:28
No.


427
00:27:28 --> 00:27:37
Suppose, for example, you had
the letters this, doglets.

428
00:27:37 --> 00:27:41
Well, the highest scoring word
might have been something like

429
00:27:41 --> 00:27:50
Doges, these guys used to rule
Venice, but if you did that

430
00:27:50 --> 00:27:55
you'd been left with the
letters l and t, which

431
00:27:55 --> 00:27:58
are kind of hard to use.


432
00:27:58 --> 00:28:00
So you've optimized
the first step.

433
00:28:00 --> 00:28:02
But now you're stuck
with something that's

434
00:28:02 --> 00:28:04
not very useful.


435
00:28:04 --> 00:28:10
Whereas in fact, maybe you
would have been better to go

436
00:28:10 --> 00:28:19
with dog, dogs, and let.


437
00:28:19 --> 00:28:24
So what we see here is an
example of something very

438
00:28:24 --> 00:28:27
important and quite general.


439
00:28:27 --> 00:28:49
Which was that locally optimal
decisions do not always

440
00:28:49 --> 00:29:02
lead to a global optimums.


441
00:29:02 --> 00:29:07
So you can't just repeatedly do
the apparently local thing and

442
00:29:07 --> 00:29:11
expect to necessarily
get to it.

443
00:29:11 --> 00:29:14
Now, as it happens with the
continuous knapsack problem

444
00:29:14 --> 00:29:21
as we've formulated
it, greedy is good.

445
00:29:21 --> 00:29:26
But let's look for a slight
variant of it, where

446
00:29:26 --> 00:29:30
greedy is not so good.


447
00:29:30 --> 00:29:56
And that's what's called the
zero-one knapsack problem.

448
00:29:56 --> 00:29:59
This is basically a
discrete version of

449
00:29:59 --> 00:30:02
the knapsack problem.


450
00:30:02 --> 00:30:12
The formulation is that we have
n items and at every step we

451
00:30:12 --> 00:30:18
have to either take the whole
item or none of the item.

452
00:30:18 --> 00:30:21
In the continuous problem,
the gold dust was assumed

453
00:30:21 --> 00:30:23
to be infinitely small.


454
00:30:23 --> 00:30:27
And so you could take as
much of it as you wanted.

455
00:30:27 --> 00:30:30
Here it's as if you
had gold bricks.

456
00:30:30 --> 00:30:36
You get to take the whole
brick or no brick at all.

457
00:30:36 --> 00:30:41
Each item has a weight and
a value, and we're trying

458
00:30:41 --> 00:30:43
to optimize it as before.


459
00:30:43 --> 00:30:47
So let's look at an example of
a zero-one knapsack problem.

460
00:30:47 --> 00:30:51
Again we'll go back
to our burglar.

461
00:30:51 --> 00:31:00
So the burglar breaks into
the house and finds the

462
00:31:00 --> 00:31:02
following items available.


463
00:31:02 --> 00:31:05
And you'll see in your handout
a list of items and their value

464
00:31:05 --> 00:31:08
and how much, what they weight.


465
00:31:08 --> 00:31:13
Finds a watch, a nice Bose
radio, a beautiful Tiffany

466
00:31:13 --> 00:31:19
vase, and a large velvet Elvis.


467
00:31:19 --> 00:31:23
And now this burglar finds, in
fact, two of each of those.

468
00:31:23 --> 00:31:26
Person is a real velvet
Elvis fan and needed

469
00:31:26 --> 00:31:28
two copies of this one.


470
00:31:28 --> 00:31:35
Alright, and now he's trying
to decide what to take.

471
00:31:35 --> 00:31:37
Well if the knapsack were large
enough the thief would take it

472
00:31:37 --> 00:31:40
all and run, but let's assume
that it can only hold

473
00:31:40 --> 00:31:43
eight pounds, as before.


474
00:31:43 --> 00:31:46
And therefore the thief
has choices to make.

475
00:31:46 --> 00:31:49
Well, there are three types of
thieves I want to consider:

476
00:31:49 --> 00:31:57
the greedy thief, the
slow thief, and you.

477
00:31:57 --> 00:32:00
We'll start with
the greedy thief.

478
00:32:00 --> 00:32:03
Well, the greedy thief follows
the greedy algorithm.

479
00:32:03 --> 00:32:05
What do you get if you follow
the greedy algorithm?

480
00:32:05 --> 00:32:07
What's the first thing
the thief does?

481
00:32:07 --> 00:32:14
Takes the most valuable
item, which is a watch.

482
00:32:14 --> 00:32:18
And then what does
he do after that?

483
00:32:18 --> 00:32:19
Takes another watch.


484
00:32:19 --> 00:32:22
And then?


485
00:32:22 --> 00:32:22
Pardon?


486
00:32:22 --> 00:32:24
STUDENT: [INAUDIBLE]


487
00:32:24 --> 00:32:24
PROFESSOR: And then?


488
00:32:24 --> 00:32:28
STUDENT: [INAUDIBLE]


489
00:32:28 --> 00:32:29
PROFESSOR: No.


490
00:32:29 --> 00:32:32
Not unless he wants to break
the vase into little pieces

491
00:32:32 --> 00:32:34
and stuff it in the corners.


492
00:32:34 --> 00:32:38
The backpack is
now full, right?

493
00:32:38 --> 00:32:41
There's no more room.


494
00:32:41 --> 00:32:45
So the greedy thief
take that and leaves.

495
00:32:45 --> 00:32:52
But it's not an
optimal solution.

496
00:32:52 --> 00:32:55
What should the
thief have done?

497
00:32:55 --> 00:32:57
What's the best
thing you can do?

498
00:32:57 --> 00:33:00
Instead of taking that one
vase, the thief could

499
00:33:00 --> 00:33:03
take two radios.


500
00:33:03 --> 00:33:06
And get more value.


501
00:33:06 --> 00:33:12
So the greedy thief, in some
sense, gets the wrong answer.

502
00:33:12 --> 00:33:16
But maybe isn't so dumb.


503
00:33:16 --> 00:33:19
While greedy algorithms are not
guaranteed to get you the right

504
00:33:19 --> 00:33:25
answer all the time, they're
often very good to use.

505
00:33:25 --> 00:33:31
And what they're good about is,
they're easy to implement.

506
00:33:31 --> 00:33:34
And they're fast to run.


507
00:33:34 --> 00:33:37
You can imagine coding
the solution up and

508
00:33:37 --> 00:33:39
it's pretty easy.


509
00:33:39 --> 00:33:42
And when it runs,
it's pretty fast.

510
00:33:42 --> 00:33:46
Just takes the most valuable,
the next most valuable, the

511
00:33:46 --> 00:33:47
next most valuable, I'm done.


512
00:33:47 --> 00:33:51
And the thief leaves,
and is gone.

513
00:33:51 --> 00:33:53
So that's a good thing.


514
00:33:53 --> 00:33:56
On the other hand, it's often
the case in the world that

515
00:33:56 --> 00:33:59
that's not good enough.


516
00:33:59 --> 00:34:01
And we're not looking for an OK
solution, but we're looking

517
00:34:01 --> 00:34:04
for the best solution.


518
00:34:04 --> 00:34:08
Optimal means best.


519
00:34:08 --> 00:34:11
And that's what the
slow thief does.

520
00:34:11 --> 00:34:14
So the slow thief
thinks the following.

521
00:34:14 --> 00:34:19
Well, what I'll do is I'll
put stuff in the backpack

522
00:34:19 --> 00:34:21
until it's full.


523
00:34:21 --> 00:34:24
I'll compute its value.


524
00:34:24 --> 00:34:28
Then I'll empty the backpack
out, put another combination of

525
00:34:28 --> 00:34:32
stuff compute its value, try
all possible ways of filling up

526
00:34:32 --> 00:34:36
the backpack, and then when
I'm done, I'll know

527
00:34:36 --> 00:34:37
which was the best.


528
00:34:37 --> 00:34:40
And that's the one I'll do.


529
00:34:40 --> 00:34:43
So he's packing and unpacking,
packing and unpacking, trying

530
00:34:43 --> 00:34:46
all possible combinations
of objects that will

531
00:34:46 --> 00:34:48
obey the constraint.


532
00:34:48 --> 00:34:51
And then choosing the winner.


533
00:34:51 --> 00:34:53
Well, this is like an
algorithm we've seen before.

534
00:34:53 --> 00:34:54
It's not greedy.


535
00:34:54 --> 00:34:56
What is this?


536
00:34:56 --> 00:34:59
What category of
algorithm is that?

537
00:34:59 --> 00:35:01
Somebody?


538
00:35:01 --> 00:35:02
Louder?


539
00:35:02 --> 00:35:04
STUDENT: Brute force.


540
00:35:04 --> 00:35:05
PROFESSOR: Brute
force, exhaustive

541
00:35:05 --> 00:35:07
enumeration, exactly.


542
00:35:07 --> 00:35:09
We're exhausting
all possibilities.

543
00:35:09 --> 00:35:12
And then choosing the winner.


544
00:35:12 --> 00:35:15
Well, that's what the
slow thief tried.

545
00:35:15 --> 00:35:19
Unfortunately it took so long
that before he finished

546
00:35:19 --> 00:35:21
the owner returned home,
called the police and the

547
00:35:21 --> 00:35:23
thief ended up in jail.


548
00:35:23 --> 00:35:25
It happens.


549
00:35:25 --> 00:35:30
Fortunately, while sitting in
jail awaiting trial, the slow

550
00:35:30 --> 00:35:34
thief decided to figure
what was wrong.

551
00:35:34 --> 00:35:37
And, amazingly enough, he
had studied mathematics.

552
00:35:37 --> 00:35:40
And had a blackboard
in the cell.

553
00:35:40 --> 00:35:43
So he was able to work it out.


554
00:35:43 --> 00:35:47
So he first said, well, let me
try and figure out what I was

555
00:35:47 --> 00:35:50
really doing and why
it took so long.

556
00:35:50 --> 00:35:56
So first, let's think about
what was the function

557
00:35:56 --> 00:36:02
the slow thief was
attempting to maximize.

558
00:36:02 --> 00:36:10
The summation, from i equals 1
to n, where n is the number of

559
00:36:10 --> 00:36:20
items, so I might label watch
1-0, watch 2-2, I don't care

560
00:36:20 --> 00:36:21
that they're both watches.


561
00:36:21 --> 00:36:24
They're two separate items.


562
00:36:24 --> 00:36:28
And then what I want to
maximize is the sum of the

563
00:36:28 --> 00:36:40
price of item i times
whether or not I took x i.

564
00:36:40 --> 00:36:51
So think of x as a
vector of 0's and 1's.

565
00:36:51 --> 00:36:54
Hence the name of the problem.


566
00:36:54 --> 00:36:57
If I'm going to keep that
item, item i, if I'm going

567
00:36:57 --> 00:36:59
to take it, I give it a 1.


568
00:36:59 --> 00:37:03
If I'm not going to
take it I give it a 0.

569
00:37:03 --> 00:37:07
And so I just take the value
of that item times whether

570
00:37:07 --> 00:37:11
or not it's 0 or 1.


571
00:37:11 --> 00:37:19
So my goal here is to choose x
such that this is maximized.

572
00:37:19 --> 00:37:24
Choose x such that that
function is maximized,

573
00:37:24 --> 00:37:28
subject to a constraint.


574
00:37:28 --> 00:37:48
And the constraint, is it the
sum from 1 to n of the weight

575
00:37:48 --> 00:37:58
of the item, times x i, is less
than or equal to c, the maximum

576
00:37:58 --> 00:38:00
weight I'm allowed to
put in my backpack.

577
00:38:00 --> 00:38:04
In this case it was eight.


578
00:38:04 --> 00:38:08
So now I have a nice, tidy
mathematical formulation

579
00:38:08 --> 00:38:10
of the problem.


580
00:38:10 --> 00:38:14
And that's often the first
step in problem reduction.

581
00:38:14 --> 00:38:18
Is to go from a problem that
has a bunch of words, and try

582
00:38:18 --> 00:38:23
and write it down as a nice,
tight mathematical formulation.

583
00:38:23 --> 00:38:28
So now I know the formulation
is to find x, the vector x,

584
00:38:28 --> 00:38:31
such that this constraint
is obeyed and this

585
00:38:31 --> 00:38:37
function is maximized.


586
00:38:37 --> 00:38:38
That make sense to everybody?


587
00:38:38 --> 00:38:42
Any questions about that?


588
00:38:42 --> 00:38:45
Great.


589
00:38:45 --> 00:38:51
So as the thief had thought, we
can clearly solve this problem

590
00:38:51 --> 00:38:58
by generating all possible
values of x and seeing which

591
00:38:58 --> 00:39:03
one solves this problem.


592
00:39:03 --> 00:39:06
But now the thief started
scratching his head and said,

593
00:39:06 --> 00:39:13
well, how many possible
values of x are there?

594
00:39:13 --> 00:39:19
Well, how can we
think about that?

595
00:39:19 --> 00:39:23
Well, a nice way to think
about that is to say,

596
00:39:23 --> 00:39:25
I've got a vector.


597
00:39:25 --> 00:39:32
So there's the vector
with eight 0's in it.

598
00:39:32 --> 00:39:36
Three, four, five,
six, seven, eight.

599
00:39:36 --> 00:39:44
Indicating I didn't
take any of the items.

600
00:39:44 --> 00:39:48
There's the vector, and again
you'll see this in your

601
00:39:48 --> 00:39:55
handout, says I only
took the first item.

602
00:39:55 --> 00:40:00
There's the one that says I
only took the second item.

603
00:40:00 --> 00:40:02
There's the one that says
I took the first and

604
00:40:02 --> 00:40:05
the second item.


605
00:40:05 --> 00:40:09
And at the last,
I have all 1's.

606
00:40:09 --> 00:40:12
This series look like
anything familiar to you?

607
00:40:12 --> 00:40:15
These are binary
numbers, right?

608
00:40:15 --> 00:40:16
Eight digit binary numbers.


609
00:40:16 --> 00:40:21
Zero, one, two, three.


610
00:40:21 --> 00:40:26
What's the biggest number I can
represent with eight of these?

611
00:40:26 --> 00:40:31
Somebody?


612
00:40:31 --> 00:40:34
Well, suppose we had
decimal numbers.

613
00:40:34 --> 00:40:37
And I said I'm giving you
three decimal digits.

614
00:40:37 --> 00:40:38
What's the biggest number
you can represent with

615
00:40:38 --> 00:40:43
three decimal digits?


616
00:40:43 --> 00:40:43
Pardon?


617
00:40:43 --> 00:40:45
STUDENT: [INAUDIBLE]


618
00:40:45 --> 00:40:47
PROFESSOR: Right.


619
00:40:47 --> 00:40:50
Which is roughly what?


620
00:40:50 --> 00:40:51
10 to the?


621
00:40:51 --> 00:40:55
STUDENT: [INAUDIBLE]


622
00:40:55 --> 00:40:58
PROFESSOR: Right.


623
00:40:58 --> 00:40:58
Yes.


624
00:40:58 --> 00:41:01
STUDENT: [INAUDIBLE]


625
00:41:01 --> 00:41:01
PROFESSOR: Right.


626
00:41:01 --> 00:41:03
Exactly right.


627
00:41:03 --> 00:41:07
So, in this case
it's 2 to the 8th.

628
00:41:07 --> 00:41:08
Because I have eight digits.


629
00:41:08 --> 00:41:11
But exactly right.


630
00:41:11 --> 00:41:18
More generally,
it's 2 to the n.

631
00:41:18 --> 00:41:21
Where n is the number
of possible items I

632
00:41:21 --> 00:41:26
have to choose from.


633
00:41:26 --> 00:41:33
Well, now that we've figured
that out, what we're seeing

634
00:41:33 --> 00:41:42
is that the brute force
algorithm is exponential.

635
00:41:42 --> 00:41:46
In the number of items
we have to choose from.

636
00:41:46 --> 00:41:49
Not in the number that we
take, but the number we

637
00:41:49 --> 00:41:52
have to think about taking.


638
00:41:52 --> 00:41:57
Exponential growth
is a scary thing.

639
00:41:57 --> 00:42:03
So now we can look at these two
graphs, look at the top one.

640
00:42:03 --> 00:42:10
So there, we've compared n
squared, quadratic growth,

641
00:42:10 --> 00:42:14
which by the way Professor
Grimson told you was bad,

642
00:42:14 --> 00:42:19
to, really bad, which
is exponential growth.

643
00:42:19 --> 00:42:22
And in fact, if you look at
the top figure it looks as

644
00:42:22 --> 00:42:27
exponential or, quadratic
isn't even growing at all.

645
00:42:27 --> 00:42:31
You see how really fast
exponential growth is?

646
00:42:31 --> 00:42:34
You get to fifteen items and
we're up at seventy thousand

647
00:42:34 --> 00:42:39
already and counting.


648
00:42:39 --> 00:42:42
The bottom graph has
exactly the same data.

649
00:42:42 --> 00:42:47
But what I've done is, I've
use the logarithmic y-axis.

650
00:42:47 --> 00:42:49
Later in the term, we'll spend
quite a lot of time talking

651
00:42:49 --> 00:42:52
about how do we visualize data.


652
00:42:52 --> 00:42:54
How do we make sense of data.


653
00:42:54 --> 00:42:57
I've done that because you can
see here that the quadratic

654
00:42:57 --> 00:42:59
one is actually growing.


655
00:42:59 --> 00:43:05
It's just growing a
lot more slowly.

656
00:43:05 --> 00:43:08
So the moral here
is simple one.

657
00:43:08 --> 00:43:15
Exponential algorithms are
typically not useful. n does

658
00:43:15 --> 00:43:21
not have to get very big
for exponential to fail.

659
00:43:21 --> 00:43:25
Now, imagine that you're trying
to pack a ship and you've got

660
00:43:25 --> 00:43:27
ten thousand items
to choose from.

661
00:43:27 --> 00:43:34
2 to the 10,000 is a
really big number.

662
00:43:34 --> 00:43:39
So what we see immediately, and
the slow thief decided just

663
00:43:39 --> 00:43:44
before being incarcerated for
years and years, was that it

664
00:43:44 --> 00:43:47
wasn't possible to
do it that way.

665
00:43:47 --> 00:43:51
He threw up his hands and said,
it's an unsolvable problem,

666
00:43:51 --> 00:43:55
I should have been greedy,
there's no good way to do this.

667
00:43:55 --> 00:43:58
That gets us to
the smart thief.

668
00:43:58 --> 00:43:59
Why is this thief smart?


669
00:43:59 --> 00:44:02
Because she took 600.


670
00:44:02 --> 00:44:04
And she learned that in fact
there is a good way to

671
00:44:04 --> 00:44:06
solve this problem.


672
00:44:06 --> 00:44:10
And that's what we're
going to talk about next.

673
00:44:10 --> 00:44:23
And that's something called
dynamic programming.

674
00:44:23 --> 00:44:26
A lot of people think this is a
really hard and fancy concept,

675
00:44:26 --> 00:44:29
and they teach in advanced
algorithms classes.

676
00:44:29 --> 00:44:31
And they do, but in fact
as you'll see it's

677
00:44:31 --> 00:44:33
really pretty simple.


678
00:44:33 --> 00:44:35
A word of warning.


679
00:44:35 --> 00:44:37
Don't try and figure
out why it's called

680
00:44:37 --> 00:44:39
dynamic programming.


681
00:44:39 --> 00:44:41
It makes no sense at all.


682
00:44:41 --> 00:44:45
It was invented by a
mathematician called Bellman.

683
00:44:45 --> 00:44:49
And he was at the time being
paid by the Defense Department

684
00:44:49 --> 00:44:51
to work on something else.


685
00:44:51 --> 00:44:54
And he didn't want them to
know what he was doing.

686
00:44:54 --> 00:44:56
So he made up a name that he
was sure they would have

687
00:44:56 --> 00:44:58
no clue what it meant.


688
00:44:58 --> 00:45:02
Unfortunately, we now have
lived with it forever, so don't

689
00:45:02 --> 00:45:05
think of it as actually being
anything dynamic particularly.

690
00:45:05 --> 00:45:09
It's just a name.


691
00:45:09 --> 00:45:13
It's very useful, and why we
spend time on it for solving

692
00:45:13 --> 00:45:18
a broad range of problems
that on their surface are

693
00:45:18 --> 00:45:20
exponentially difficult.


694
00:45:20 --> 00:45:25
And, in fact, getting very
fast solutions to them.

695
00:45:25 --> 00:45:28
The key thing in dynamic
programming, and we'll return

696
00:45:28 --> 00:45:32
to both of these, is you're
looking for a situation where

697
00:45:32 --> 00:45:45
there are overlapping
sub-problems and what's called

698
00:45:45 --> 00:45:47
optimal substructure.


699
00:45:47 --> 00:45:49
Don't expect to know
what these mean yet.

700
00:45:49 --> 00:45:52
Hopefully by the end of the
day, Tuesday, they will both

701
00:45:52 --> 00:45:55
make great sense to you.


702
00:45:55 --> 00:45:56
Let's first look at
the overlapping

703
00:45:56 --> 00:45:59
sub-problems example.


704
00:45:59 --> 00:46:05
You have on your handout, a
recursive implementation

705
00:46:05 --> 00:46:07
of Fibonacci.


706
00:46:07 --> 00:46:25
Which we've seen before.


707
00:46:25 --> 00:46:28
What I've done is I've
augmented it with this global

708
00:46:28 --> 00:46:32
called num calls just so I can
keep track of how many

709
00:46:32 --> 00:46:34
times it gets called.


710
00:46:34 --> 00:46:48
And let's see what happens
if we call fib of 5.

711
00:46:48 --> 00:46:53
Well, quite a few steps.


712
00:46:53 --> 00:47:00
What's the thing that you
notice about this output?

713
00:47:00 --> 00:47:03
There's something here that
should tip us off that maybe

714
00:47:03 --> 00:47:09
we're not doing this the most
efficient way possible.

715
00:47:09 --> 00:47:15
I called fib with 5 and
then it calls it with 4.

716
00:47:15 --> 00:47:17
And then that call
calls fib with 3.

717
00:47:17 --> 00:47:21
So I'm doing 4, 3, 2, 2, 1, 0.


718
00:47:21 --> 00:47:22
And I'm doing 1, 2.


719
00:47:22 --> 00:47:26
Well, what we see is I'm
calling fib a lot of times

720
00:47:26 --> 00:47:30
with the same argument.


721
00:47:30 --> 00:47:31
And it makes sense.


722
00:47:31 --> 00:47:35
Because I start with fib of
5, and then I have to do

723
00:47:35 --> 00:47:39
fib of 4 and fib of 3.


724
00:47:39 --> 00:47:43
Well, fib of 4 is going to also
have to do a fib of 3 and a

725
00:47:43 --> 00:47:46
fib of 2 and a fib of
1, and a fib of 0.

726
00:47:46 --> 00:47:48
And then the fib of 3 is
going to do a fib of 2 and

727
00:47:48 --> 00:47:51
a fib of 1 and a fib of 0.


728
00:47:51 --> 00:47:56
And so I'm doing the same
thing over and over again.

729
00:47:56 --> 00:47:59
That's because I have what
are called overlapping

730
00:47:59 --> 00:48:01
sub-problems.


731
00:48:01 --> 00:48:05
I have used divide and conquer,
as we seen before, to

732
00:48:05 --> 00:48:08
recursively break it
into smaller problems.

733
00:48:08 --> 00:48:12
But the smaller problem of fib
of 4 and the smaller problem of

734
00:48:12 --> 00:48:16
fib of 3 overlap
with each other.

735
00:48:16 --> 00:48:21
And that leads to a lot of
redundant computation.

736
00:48:21 --> 00:48:24
And I've done fib of 5,
which is a small number.

737
00:48:24 --> 00:48:28
If we look at some other
things, for example,

738
00:48:28 --> 00:48:39
let's get rid of this.


739
00:48:39 --> 00:48:56
Let's try see fib of 10.


740
00:48:56 --> 00:49:02
Well, there's a reason I chose
10 rather than, say, 20.

741
00:49:02 --> 00:49:09
Here fib got called 177 times.


742
00:49:09 --> 00:49:13
Roughly speaking, the analysis
of fib is actually quite

743
00:49:13 --> 00:49:15
complex, of a recursive fib.


744
00:49:15 --> 00:49:17
And I won't go through it,
but what you can see is

745
00:49:17 --> 00:49:21
it's more or less, it is
in fact, exponential.

746
00:49:21 --> 00:49:23
But it's not 2 to
the something.

747
00:49:23 --> 00:49:26
It's a more complicated thing.


748
00:49:26 --> 00:49:29
But it grows quite quickly.


749
00:49:29 --> 00:49:34
And the reason it does is
because of this overlapping.

750
00:49:34 --> 00:49:38
On Tuesday we'll talk about a
different way to implement

751
00:49:38 --> 00:49:44
Fibonacci, where the growth
will be much less dramatic.

752
00:49:44 --> 00:49:46
Thank you.


753
00:49:46 --> 00:49:46




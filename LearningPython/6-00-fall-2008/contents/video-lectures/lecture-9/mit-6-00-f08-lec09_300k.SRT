1
00:00:00 --> 00:00:00



2
00:00:00 --> 00:00:02
ANNOUNCER: Open content is
provided under a creative

3
00:00:02 --> 00:00:03
commons license.


4
00:00:03 --> 00:00:06
Your support will help MIT
OpenCourseWare continue to

5
00:00:06 --> 00:00:10
offer High-quality educational
resources for free.

6
00:00:10 --> 00:00:13
To make a donation, or view
additional materials from

7
00:00:13 --> 00:00:17
hundreds of MIT courses,
visit MIT OpenCourseWare

8
00:00:17 --> 00:00:19
at ocw.mit.edu.


9
00:00:19 --> 00:00:23
PROFESSOR ERIC GRIMSON:
Let's recap where we were.

10
00:00:23 --> 00:00:25
Last lecture, we talked
about, or started to

11
00:00:25 --> 00:00:27
talk about, efficiency.


12
00:00:27 --> 00:00:28
Orders of growth.


13
00:00:28 --> 00:00:30
Complexity.


14
00:00:30 --> 00:00:33
And I'll remind you, we saw a
set of algorithms, and part of

15
00:00:33 --> 00:00:36
my goal was to get you to begin
to recognize characteristics of

16
00:00:36 --> 00:00:40
algorithms that map into
a particular class.

17
00:00:40 --> 00:00:40
So what did we see?


18
00:00:40 --> 00:00:42
We saw linear algorithms.


19
00:00:42 --> 00:00:45
Typical characterization, not
all the time, but typical

20
00:00:45 --> 00:00:49
characterization, is an
algorithm that reduces the size

21
00:00:49 --> 00:00:54
of a problem by one, or by some
constant amount each time, is

22
00:00:54 --> 00:00:57
typically an example of
a linear algorithm.

23
00:00:57 --> 00:01:00
And we saw a couple of examples
of linear algorithms.

24
00:01:00 --> 00:01:03
We also saw a logarithmic
algorithm. and we like

25
00:01:03 --> 00:01:05
log algorithms, because
they're really fast.

26
00:01:05 --> 00:01:09
A typical characteristic of a
log algorithm is a pro-- or

27
00:01:09 --> 00:01:12
sorry, an algorithm where
it reduces the size of the

28
00:01:12 --> 00:01:14
problem by a constant factor.


29
00:01:14 --> 00:01:16
Obviously-- and that's a bad
way of saying it, I said

30
00:01:16 --> 00:01:18
constant the previous time--
in the linear case, it's

31
00:01:18 --> 00:01:19
subtract by certain amount.


32
00:01:19 --> 00:01:21
In the log case, it's
divide by an amount.

33
00:01:21 --> 00:01:23
Cut the problem in half.


34
00:01:23 --> 00:01:25
Cut the problem in half again.


35
00:01:25 --> 00:01:26
And that's a typical
characterization of

36
00:01:26 --> 00:01:28
a log algorithm.


37
00:01:28 --> 00:01:31
We saw some quadratic
algorithms, typically those are

38
00:01:31 --> 00:01:33
things with multiple nested
loops, or iterative or

39
00:01:33 --> 00:01:36
recursive calls, where you're
doing, say, a linear amount of

40
00:01:36 --> 00:01:39
time but you're doing it a
linear number of times, and so

41
00:01:39 --> 00:01:42
it becomes quadratic, and
you'll see other polynomial

42
00:01:42 --> 00:01:43
kinds of algorithms.


43
00:01:43 --> 00:01:46
And finally, we saw an example
of an exponential algorithm,

44
00:01:46 --> 00:01:48
those Towers of Hanoi.


45
00:01:48 --> 00:01:51
We don't like exponential
algorithms, or at least you

46
00:01:51 --> 00:01:53
shouldn't like them, because
they blow up quickly.

47
00:01:53 --> 00:01:55
And we saw some
examples of that.

48
00:01:55 --> 00:01:58
And unfortunately, some
problems are inherently

49
00:01:58 --> 00:02:00
exponential, you're sort of
stuck with that, and then

50
00:02:00 --> 00:02:03
you just have to try be
as clever as you can.

51
00:02:03 --> 00:02:04
OK.


52
00:02:04 --> 00:02:07
At the end of the lecture last
time, I also showed you an

53
00:02:07 --> 00:02:09
example of binary search.


54
00:02:09 --> 00:02:12
And I want to redo that in a
little more detail today,

55
00:02:12 --> 00:02:15
because I felt like I did that
a little more quickly than I

56
00:02:15 --> 00:02:18
wanted to, so, if you really
got binary search, fall asleep

57
00:02:18 --> 00:02:21
for about ten minutes, just
don't snore, your neighbors may

58
00:02:21 --> 00:02:22
not appreciate it, but we're
going to go over it again,

59
00:02:22 --> 00:02:24
because it's a problem and an
idea that we're going to come

60
00:02:24 --> 00:02:27
back to, and I really want to
make sure that I do this in a

61
00:02:27 --> 00:02:30
way that makes real
good sense you.

62
00:02:30 --> 00:02:31
Again.


63
00:02:31 --> 00:02:34
Basic premise of binary search,
or at least we set it up was,

64
00:02:34 --> 00:02:37
imagine I have a sorted
list of elements.

65
00:02:37 --> 00:02:39
We get, in a second, to how
we're going to get them sorted,

66
00:02:39 --> 00:02:43
and I want to know, is a
particular element

67
00:02:43 --> 00:02:44
in that list..


68
00:02:44 --> 00:02:47
And the basic idea of binary
search is to start with the

69
00:02:47 --> 00:02:50
full range of the list, pick
the midpoint, and

70
00:02:50 --> 00:02:53
test that point.


71
00:02:53 --> 00:02:54
If it's the thing I'm
looking for, I'm golden.

72
00:02:54 --> 00:02:58
If not, because the list
is sorted, I can use the

73
00:02:58 --> 00:03:01
difference between what I'm
looking for and that midpoint

74
00:03:01 --> 00:03:04
to decide, should I look in the
top half of the list, or the

75
00:03:04 --> 00:03:05
bottom half of the list?


76
00:03:05 --> 00:03:06
And I keep chopping it down.


77
00:03:06 --> 00:03:09
And I want to show you a little
bit more detail of that, so

78
00:03:09 --> 00:03:11
let's create a simple
little list here.

79
00:03:11 --> 00:03:22
All right?


80
00:03:22 --> 00:03:25
I don't care what's in there,
but just assume that's my list.

81
00:03:25 --> 00:03:28
And just to remind you, on your
handout, and there it is on the

82
00:03:28 --> 00:03:31
screen, I'm going to bring it
back up, there's the little

83
00:03:31 --> 00:03:32
binary search algorithm.


84
00:03:32 --> 00:03:34
We're going to call search,
which just calls binary search.

85
00:03:34 --> 00:03:38
And you can look at it, and
let's in fact take a look

86
00:03:38 --> 00:03:40
at it to see what it does.


87
00:03:40 --> 00:03:42
We're going to call binary
search, it's going to take the

88
00:03:42 --> 00:03:46
list to search and the element,
but it's also going to say,

89
00:03:46 --> 00:03:52
here's the first part of the
list, and there's the last part

90
00:03:52 --> 00:03:55
of the list, and what does
it do inside that code?

91
00:03:55 --> 00:03:57
Well, it checks to see,
is it bigger than two?

92
00:03:57 --> 00:03:59
Are there more than
two elements there?

93
00:03:59 --> 00:04:01
If there are less than two
elements there, I just check

94
00:04:01 --> 00:04:03
one or both of those to see
if I'm looking for

95
00:04:03 --> 00:04:04
the right thing.


96
00:04:04 --> 00:04:06
Otherwise, what does
that code say to do?

97
00:04:06 --> 00:04:10
It says find the midpoint,
which says, take the start,

98
00:04:10 --> 00:04:15
which is pointing to that place
right there, take last minus

99
00:04:15 --> 00:04:17
first, divide it by 2,
and add it to start.

100
00:04:17 --> 00:04:21
And that basically,
somewhere about here,

101
00:04:21 --> 00:04:23
gives me the midpoint.


102
00:04:23 --> 00:04:25
Now I look at that element.


103
00:04:25 --> 00:04:26
Is it the thing
I'm looking for?

104
00:04:26 --> 00:04:29
If I'm really lucky, it is.


105
00:04:29 --> 00:04:32
If not, I look at the value
of that point here and the

106
00:04:32 --> 00:04:34
thing I'm looking for.


107
00:04:34 --> 00:04:36
And for sake of argument, let's
assume that the thing I'm

108
00:04:36 --> 00:04:39
looking for is smaller
than the value here.

109
00:04:39 --> 00:04:41
Here's what I do.


110
00:04:41 --> 00:04:42
I change-- oops!


111
00:04:42 --> 00:04:48
Let me do that this way-- I
change last to here, and

112
00:04:48 --> 00:04:54
keep first there, and I
throw away all of that.

113
00:04:54 --> 00:04:56
All right?


114
00:04:56 --> 00:04:59
That's just the those-- let
me use my pointer-- that's

115
00:04:59 --> 00:05:01
just these two lines here.


116
00:05:01 --> 00:05:05
I checked the value, and in one
case, I'm changing the last to

117
00:05:05 --> 00:05:09
be mid minus 1, which is the
case I'm in here, and

118
00:05:09 --> 00:05:10
I just call again.


119
00:05:10 --> 00:05:12
All right?


120
00:05:12 --> 00:05:13
I'm going to call
exactly the same thing.

121
00:05:13 --> 00:05:16
Now, first is pointing here,
last is pointing there, again,

122
00:05:16 --> 00:05:18
I check to see, are there
more than two things left?

123
00:05:18 --> 00:05:20
There are, in this case.


124
00:05:20 --> 00:05:21
So what do I do?


125
00:05:21 --> 00:05:23
I find the midpoint by taking
last minus first, divide

126
00:05:23 --> 00:05:25
by 2, and add to start.


127
00:05:25 --> 00:05:29
Just for sake of argument,
we'll assume it's about there,

128
00:05:29 --> 00:05:31
and I do the same thing.


129
00:05:31 --> 00:05:33
Is this value what
I'm looking for?

130
00:05:33 --> 00:05:35
Again, for sake of argument,
let's assume it's not.

131
00:05:35 --> 00:05:38
Let's assume, for sake of
argument, the thing I'm looking

132
00:05:38 --> 00:05:40
for is bigger than this.


133
00:05:40 --> 00:05:43
In that case, I'm going to
throw away all of this, I'm

134
00:05:43 --> 00:05:46
going to hit that bottom
line of that code.

135
00:05:46 --> 00:05:47
Ah.


136
00:05:47 --> 00:05:48
What does that do?


137
00:05:48 --> 00:05:49
It changes the call.


138
00:05:49 --> 00:05:56
So in this case, first
now points there,

139
00:05:56 --> 00:06:00
last points there.


140
00:06:00 --> 00:06:01
And I cut around.


141
00:06:01 --> 00:06:07
And again, notice
what I've done.

142
00:06:07 --> 00:06:09
I've thrown away most of the
array-- most of the list, I

143
00:06:09 --> 00:06:11
shouldn't say array--
most of the list.

144
00:06:11 --> 00:06:12
All right?


145
00:06:12 --> 00:06:16
So it cuts it down
quickly as we go along.

146
00:06:16 --> 00:06:18
OK.


147
00:06:18 --> 00:06:20
That's the basic idea
of binary search.

148
00:06:20 --> 00:06:23
And let's just run a couple
of examples to remind you of

149
00:06:23 --> 00:06:27
what happens if we do this.


150
00:06:27 --> 00:06:29
So if I call, let's
[UNINTELLIGIBLE], let's set

151
00:06:29 --> 00:06:37
up s to be, I don't know,
some big long list.

152
00:06:37 --> 00:06:37
OK.


153
00:06:37 --> 00:06:41
And I'm going to look to see,
is a particular element inside

154
00:06:41 --> 00:06:47
of that list, and again, I'll
remind you, that's just giving

155
00:06:47 --> 00:06:50
me the integers from zero up
to 9999 something or other.

156
00:06:50 --> 00:06:56
If I look for, say, minus 1,
you might go, gee, wait a

157
00:06:56 --> 00:06:58
minute, if I was just doing
linear search, I would've known

158
00:06:58 --> 00:07:01
right away that minus one
wasn't in this list, because

159
00:07:01 --> 00:07:03
it's sorted and it's smaller
than the first elements.

160
00:07:03 --> 00:07:06
So this looks like it's doing a
little bit of extra work, but

161
00:07:06 --> 00:07:08
you can see, if you look at
that, how it cuts it

162
00:07:08 --> 00:07:09
down at each stage.


163
00:07:09 --> 00:07:12
And I'll remind you, what I'm
printing out there is, first

164
00:07:12 --> 00:07:16
and last, with the range I'm
looking over, and then just

165
00:07:16 --> 00:07:20
how many times the
iteration called.

166
00:07:20 --> 00:07:22
So in this case, it just keeps
chopping down from the back

167
00:07:22 --> 00:07:24
end, which kind of makes
sense, all right?

168
00:07:24 --> 00:07:28
But in a fixed number, in fact,
twenty-three calls, it gets

169
00:07:28 --> 00:07:30
down to the point of being able
to say whether it's there.

170
00:07:30 --> 00:07:33
Let's go the other direction.


171
00:07:33 --> 00:07:39
And yes, I guess I'd better
say s not 2, or we're going

172
00:07:39 --> 00:07:40
to get an error here.


173
00:07:40 --> 00:07:48
Again, in twenty-three checks.


174
00:07:48 --> 00:07:50
In this case, it's cutting up
from the bottom end, which

175
00:07:50 --> 00:07:52
makes sense because the thing
I'm looking for is always

176
00:07:52 --> 00:07:55
bigger than the midpoint, and
then, I don't know, let's

177
00:07:55 --> 00:07:58
pick something in between.


178
00:07:58 --> 00:08:03
Somebody want-- ah, I keep
doing that-- somebody like

179
00:08:03 --> 00:08:05
to give me a number?


180
00:08:05 --> 00:08:08
I know you'd like to give me
other things, other expression,

181
00:08:08 --> 00:08:10
somebody give me a number.


182
00:08:10 --> 00:08:11
Anybody?


183
00:08:11 --> 00:08:12
No?


184
00:08:12 --> 00:08:13
Sorry.


185
00:08:13 --> 00:08:14
Thank you.


186
00:08:14 --> 00:08:15
Good number.


187
00:08:15 --> 00:08:23
OK, walks in very quickly.


188
00:08:23 --> 00:08:24
OK?


189
00:08:24 --> 00:08:26
And if you just look at the
numbers, you can see how it

190
00:08:26 --> 00:08:29
cuts in from one side and then
the other side as it keeps

191
00:08:29 --> 00:08:31
narrowing that range, until it
gets down to the place where

192
00:08:31 --> 00:08:34
there are at most two things
left, and then it just has

193
00:08:34 --> 00:08:37
to check those two to say
whether it's there or not.

194
00:08:37 --> 00:08:39
Think about this compared
to a linear search.

195
00:08:39 --> 00:08:39
All right?


196
00:08:39 --> 00:08:41
A linear search, I start at
the beginning of the list and

197
00:08:41 --> 00:08:42
walk all the way through it.


198
00:08:42 --> 00:08:45
All right, if I'm lucky and
it's at the low end, I'll

199
00:08:45 --> 00:08:46
find it pretty quickly.


200
00:08:46 --> 00:08:49
If it's not, if it's at the far
end, I've got to go forever,

201
00:08:49 --> 00:08:51
and you saw that last time
where this thing paused for a

202
00:08:51 --> 00:08:55
little while while it actually
searched a list this big.

203
00:08:55 --> 00:08:55
OK.


204
00:08:55 --> 00:08:58
So, what do I want you
to take away from this?

205
00:08:58 --> 00:09:00
This idea of binary
search is going to be a

206
00:09:00 --> 00:09:02
really powerful tool.


207
00:09:02 --> 00:09:04
And it has this property,
again, of chopping

208
00:09:04 --> 00:09:06
things into pieces.


209
00:09:06 --> 00:09:08
So in fact, what does
that suggest about the

210
00:09:08 --> 00:09:09
order of growth here?


211
00:09:09 --> 00:09:12
What is the complexity of this?


212
00:09:12 --> 00:09:14
Yeah.


213
00:09:14 --> 00:09:14
Logarithmic.


214
00:09:14 --> 00:09:15
Why?


215
00:09:15 --> 00:09:17
STUDENT: [UNINTELLIGIBLE]


216
00:09:17 --> 00:09:18
PROFESSOR ERIC GRIMSON: Yeah.


217
00:09:18 --> 00:09:18
Thank you.


218
00:09:18 --> 00:09:20
I mean, I know I sort of said
it to you, but you're right.

219
00:09:20 --> 00:09:21
It's logarithmic, right?


220
00:09:21 --> 00:09:24
It's got that property of,
it cuts things in half.

221
00:09:24 --> 00:09:26
Here's another way to think
about why is this log.

222
00:09:26 --> 00:09:28
Actually, let me ask a
slightly different question.

223
00:09:28 --> 00:09:30
How do we know this
always stops?

224
00:09:30 --> 00:09:33
I mean, I ran three
trials here, and it did.

225
00:09:33 --> 00:09:36
But how would I reason about,
does this always stop?

226
00:09:36 --> 00:09:37
Well let's see.


227
00:09:37 --> 00:09:40
Where's the end test
on this thing?

228
00:09:40 --> 00:09:43
The end test-- and I've got the
wrong glasses on-- but it's up

229
00:09:43 --> 00:09:47
here, where I'm looking to see,
is last minus first less

230
00:09:47 --> 00:09:49
than or equal to 2?


231
00:09:49 --> 00:09:49
OK.


232
00:09:49 --> 00:09:52
So, soon as I get down to a
list that has no more than two

233
00:09:52 --> 00:09:55
elements in it, I'm done.


234
00:09:55 --> 00:09:55
Notice that.


235
00:09:55 --> 00:09:57
It's a less than or equal to.


236
00:09:57 --> 00:10:00
What if I just tested to see
if it was only, say, one?

237
00:10:00 --> 00:10:01
There was one element in there.


238
00:10:01 --> 00:10:07
Would that have worked?


239
00:10:07 --> 00:10:09
I think it depends on
whether the list is

240
00:10:09 --> 00:10:11
odd or even in length.


241
00:10:11 --> 00:10:12
Actually, that's
probably not true.

242
00:10:12 --> 00:10:14
With one, it'll probably always
get it down there, but if

243
00:10:14 --> 00:10:17
I've made it just equal to
two, I might have lost.

244
00:10:17 --> 00:10:19
So first of all, I've got to be
careful about the end test.

245
00:10:19 --> 00:10:22
But the second thing is, OK,
if it stops whenever this is

246
00:10:22 --> 00:10:26
less than two, am I convinced
that this will always halt?

247
00:10:26 --> 00:10:26
And the answer is sure.


248
00:10:26 --> 00:10:27
Because what do I do?


249
00:10:27 --> 00:10:32
At each stage, no matter which
branch, here or here, I take,

250
00:10:32 --> 00:10:35
I'm cutting down the length
of the list that I'm

251
00:10:35 --> 00:10:36
searching in half.


252
00:10:36 --> 00:10:38
All right?


253
00:10:38 --> 00:10:41
So if I start off with a list
of length n, how many times can

254
00:10:41 --> 00:10:43
I divide it by 2, until I get
to something no more

255
00:10:43 --> 00:10:45
than two left?


256
00:10:45 --> 00:10:46
Log times, right.?


257
00:10:46 --> 00:10:47
Exactly as the gentleman said.


258
00:10:47 --> 00:10:48
Oh, I'm sorry.


259
00:10:48 --> 00:10:50
You're patiently waiting
for me to reward.

260
00:10:50 --> 00:10:53
Or actually, maybe you're not.


261
00:10:53 --> 00:10:55
Thank you.


262
00:10:55 --> 00:10:56
OK.


263
00:10:56 --> 00:11:08
So this is, in fact, log.


264
00:11:08 --> 00:11:10
Now, having said that,
I actually snuck

265
00:11:10 --> 00:11:12
something by you.


266
00:11:12 --> 00:11:16
And I want to spend a couple of
minutes again reinforcing that.

267
00:11:16 --> 00:11:19
So if we look at that code,
and we were little more

268
00:11:19 --> 00:11:21
careful about this,
what did we say to do?

269
00:11:21 --> 00:11:22
We said look an-- sorry.


270
00:11:22 --> 00:11:26
Count the number of primitive
operations in each step.

271
00:11:26 --> 00:11:26
OK.


272
00:11:26 --> 00:11:30
So if I look at this code,
first of all I'm calling

273
00:11:30 --> 00:11:35
search, it just has one call,
so looks like search is

274
00:11:35 --> 00:11:37
constant, except I don't know
what happens inside

275
00:11:37 --> 00:11:38
of b search.


276
00:11:38 --> 00:11:39
So I've got to
look at b search.

277
00:11:39 --> 00:11:39
So let's see.


278
00:11:39 --> 00:11:43
The first line, that print
thing, is obviously

279
00:11:43 --> 00:11:44
constant, right?


280
00:11:44 --> 00:11:47
Just take it as a constant
amount of operations But. let's

281
00:11:47 --> 00:11:50
look at the next one here,
or is that second line?

282
00:11:50 --> 00:11:51
OK.


283
00:11:51 --> 00:11:54
If last minus first is greater
than or equal to 2-- sorry,

284
00:11:54 --> 00:11:57
less than 2, then either
look at this thing or

285
00:11:57 --> 00:11:58
look at that thing.


286
00:11:58 --> 00:12:02
And that's where I said
we've got to be careful.

287
00:12:02 --> 00:12:04
That's accessing an
element of a list.

288
00:12:04 --> 00:12:07
We have to make sure that,
in fact, that operation

289
00:12:07 --> 00:12:08
is not linear.


290
00:12:08 --> 00:12:12
So let me expand on that very
slightly, and again, we did

291
00:12:12 --> 00:12:14
this last time but I want
to do one more time.

292
00:12:14 --> 00:12:21
I have to be careful
about how I'm actually

293
00:12:21 --> 00:12:22
implementing a list.


294
00:12:22 --> 00:12:40
So, for example: in this case,
my list is a bunch of integers.

295
00:12:40 --> 00:12:42
And one of the things I could
take advantage of, is I'm only

296
00:12:42 --> 00:12:45
going to need a finite amount
of space to represent

297
00:12:45 --> 00:12:46
an integer.


298
00:12:46 --> 00:12:49
So, for example, if I want to
allow for some fairly large

299
00:12:49 --> 00:12:53
range of integers, I might say,
I need four memory cells in a

300
00:12:53 --> 00:12:54
row to represent an integer.


301
00:12:54 --> 00:12:56
All right, if it's a zero, it's
going to be a whole bunch of

302
00:12:56 --> 00:12:59
ones-- of zeroes, so one, it
may be a whole bunch of zeroes

303
00:12:59 --> 00:13:02
in the first three and then a
one at the end of this thing,

304
00:13:02 --> 00:13:05
but one of the way to think
about this list in memory, is

305
00:13:05 --> 00:13:08
that I can decide in constant
time how to find the

306
00:13:08 --> 00:13:09
i'th element of a list.


307
00:13:09 --> 00:13:12
So in particular, here's where
the zero-th element of the list

308
00:13:12 --> 00:13:15
starts, there's where the first
element starts, here's where

309
00:13:15 --> 00:13:18
the third element starts, these
are just memory cells in a row,

310
00:13:18 --> 00:13:25
and to find the zero-th
element, if start is pointing

311
00:13:25 --> 00:13:29
to that memory cell,
it's just at start.

312
00:13:29 --> 00:13:33
To find the first element,
because I know I need four

313
00:13:33 --> 00:13:41
memory cells to represent an
integer, it's at start plus 4.

314
00:13:41 --> 00:13:46
To get to the second element, I
know that that's-- you get the

315
00:13:46 --> 00:13:51
idea-- at the start plus 2
times 4, and to get to the k'th

316
00:13:51 --> 00:14:02
element, I know that I want to
take whatever the start is

317
00:14:02 --> 00:14:05
which points to that place in
memory, take care, multiply by

318
00:14:05 --> 00:14:08
4, and that tells me exactly
where to go to find

319
00:14:08 --> 00:14:09
that location.


320
00:14:09 --> 00:14:13
This may sound like a
nuance, but it's important.

321
00:14:13 --> 00:14:14
Why?


322
00:14:14 --> 00:14:16
Because that's a
constant access, right?

323
00:14:16 --> 00:14:19
To get any location in memory,
to get to any value of the

324
00:14:19 --> 00:14:23
list, I simply have to say
which element do I want to get,

325
00:14:23 --> 00:14:26
I know that these things are
stored in a particular size,

326
00:14:26 --> 00:14:29
multiply that index by 4, add
it to start, and then it's in a

327
00:14:29 --> 00:14:31
constant amount of time I
can go to that location

328
00:14:31 --> 00:14:33
and get out the cell.


329
00:14:33 --> 00:14:36
OK.


330
00:14:36 --> 00:14:41
That works nicely if I
know that I have things

331
00:14:41 --> 00:14:44
stored in constant size.


332
00:14:44 --> 00:14:47
But what if I have
a list of lists?

333
00:14:47 --> 00:14:49
What if I have a homogeneous
list, a list of integers and

334
00:14:49 --> 00:14:52
strings and floats and lists
and lists of lists and lists

335
00:14:52 --> 00:14:53
of lists of lists and all
that sort of cool stuff?

336
00:14:53 --> 00:15:04
In that case, I've got to
be a lot more careful.

337
00:15:04 --> 00:15:07
So in this case, one of the
standard ways to do this, is

338
00:15:07 --> 00:15:09
to use what's called
a linked list.

339
00:15:09 --> 00:15:14
And I'm going to do it
in the following way.

340
00:15:14 --> 00:15:21
Start again, we'll point to
the beginning of the list.

341
00:15:21 --> 00:15:23
But now, because my elements
are going to take different

342
00:15:23 --> 00:15:26
amounts of memory, I'm going
to do the following thing.

343
00:15:26 --> 00:15:31
In the first spot, I'm going to
store something that says,

344
00:15:31 --> 00:15:35
here's how far you have to jump
to get to the next element.

345
00:15:35 --> 00:15:38
And then, I'm going to use the
next sequence of things to

346
00:15:38 --> 00:15:40
represent the first element, or


347
00:15:40 --> 00:15:42
the zero-th element,
if you like.

348
00:15:42 --> 00:15:44
In this case I might need five.


349
00:15:44 --> 00:15:47
And then in the next spot, I'm
going to say how far you have

350
00:15:47 --> 00:15:49
to jump to get to
the next element.

351
00:15:49 --> 00:15:53
All right, followed by whatever
I need to represent it, which

352
00:15:53 --> 00:15:54
might only be a blank one.


353
00:15:54 --> 00:15:59
And in the next spot, maybe
I've got a really long list,

354
00:15:59 --> 00:16:01
and I'm going to say how to
jump to get to the

355
00:16:01 --> 00:16:02
next element.


356
00:16:02 --> 00:16:05
All right, this is
actually kind of nice.

357
00:16:05 --> 00:16:07
This lets me have a way of
representing things that

358
00:16:07 --> 00:16:08
could be arbitrary in size.


359
00:16:08 --> 00:16:10
And some of these things
could be huge, if they're

360
00:16:10 --> 00:16:12
themselves lists.


361
00:16:12 --> 00:16:13
Here's the problem.


362
00:16:13 --> 00:16:16
How do I get to the nth--
er, the k'th element in

363
00:16:16 --> 00:16:17
the list, in this case?


364
00:16:17 --> 00:16:20
Well I have to go to the
zero-th element, and say

365
00:16:20 --> 00:16:23
OK, gee, to get to the
next element, I've got

366
00:16:23 --> 00:16:24
to jump this here.


367
00:16:24 --> 00:16:27
And to get to the next element,
I've got to jump to here, and

368
00:16:27 --> 00:16:30
to get to the next element,
I've got to jump to here,

369
00:16:30 --> 00:16:32
until I get there.


370
00:16:32 --> 00:16:34
And so, I get some power.


371
00:16:34 --> 00:16:37
I get the ability to store
arbitrary things, but what just

372
00:16:37 --> 00:16:39
happened to my complexity?


373
00:16:39 --> 00:16:41
How long does it
take me to find the

374
00:16:41 --> 00:16:43
k'th element?


375
00:16:43 --> 00:16:44
Linear.


376
00:16:44 --> 00:16:45
Because I've got to
walk my way down it.

377
00:16:45 --> 00:16:46
OK?


378
00:16:46 --> 00:16:56
So in this case, you
have linear access.

379
00:16:56 --> 00:16:57
Oh fudge knuckle.


380
00:16:57 --> 00:16:58
Right?


381
00:16:58 --> 00:17:01
If that was the case in that
code, then my complexity is no

382
00:17:01 --> 00:17:04
longer log, because I need
linear access for each time

383
00:17:04 --> 00:17:06
I've got to go to the list, and
it's going to be much

384
00:17:06 --> 00:17:06
worse than that.


385
00:17:06 --> 00:17:08
All right.


386
00:17:08 --> 00:17:08
Now.


387
00:17:08 --> 00:17:13
Some programming languages,
primarily Lisp, actually

388
00:17:13 --> 00:17:15
store lists these ways.


389
00:17:15 --> 00:17:17
You might say, why?


390
00:17:17 --> 00:17:19
Well it turns out there's
some trade-offs to it.

391
00:17:19 --> 00:17:22
It has some advantages in terms
of power of storing things, it

392
00:17:22 --> 00:17:24
has some disadvantages,
primarily in terms

393
00:17:24 --> 00:17:26
of access time.


394
00:17:26 --> 00:17:28
Fortunately for you, Python
decided, or the investors of

395
00:17:28 --> 00:17:30
Python decided, to store
this a different way.

396
00:17:30 --> 00:17:34
And the different way is to
say, look, if I redraw this,

397
00:17:34 --> 00:17:48
it's called a box and pointer
diagram, what we really have

398
00:17:48 --> 00:17:49
for each element is two things.


399
00:17:49 --> 00:17:52
And I've actually just
reversed the order here.

400
00:17:52 --> 00:17:55
We have a pointer to the
location in memory that

401
00:17:55 --> 00:17:58
contains the actual value,
which itself might be a bunch

402
00:17:58 --> 00:18:02
of pointers, and we have a
pointer to the actual-- sorry,

403
00:18:02 --> 00:18:05
a pointer the value and we have
a pointer to the next

404
00:18:05 --> 00:18:06
element in the list.


405
00:18:06 --> 00:18:08
All right?


406
00:18:08 --> 00:18:10
And one of the things we could
do if we look at that is, we

407
00:18:10 --> 00:18:12
say, gee, we could reorganize
this in a pretty

408
00:18:12 --> 00:18:13
straightforward way.


409
00:18:13 --> 00:18:21
In particular, why don't we
just take all of the first

410
00:18:21 --> 00:18:35
cells and stick them together?


411
00:18:35 --> 00:18:40
Where now, my list is a list of
pointers, it's not a set of

412
00:18:40 --> 00:18:42
values but it's actually a
pointer off to some other

413
00:18:42 --> 00:18:44
piece of memory that
contains the value.

414
00:18:44 --> 00:18:46
Why is this nice?


415
00:18:46 --> 00:18:50
Well this is exactly like this.


416
00:18:50 --> 00:18:53
All right?


417
00:18:53 --> 00:18:57
It's now something that I can
search in constant time.

418
00:18:57 --> 00:18:58
And that's what's going
to allow me to keep this

419
00:18:58 --> 00:19:01
thing as being log.


420
00:19:01 --> 00:19:03
OK.


421
00:19:03 --> 00:19:07
With that in mind, let's
go back to where we were.

422
00:19:07 --> 00:19:10
And where were we?


423
00:19:10 --> 00:19:15
We started off talking about
binary search, and I suggested

424
00:19:15 --> 00:19:18
that this was a log algorithm,
which it is, which is

425
00:19:18 --> 00:19:21
really kind of nice.


426
00:19:21 --> 00:19:32
Let's pull together what this
algorithm actually does.

427
00:19:32 --> 00:19:35
If I generalize binary search,
here's what I'm going to

428
00:19:35 --> 00:19:37
stake that this thing does.


429
00:19:37 --> 00:19:45
It says one: pick the midpoint.


430
00:19:45 --> 00:19:56
Two: check to see if this is
the answer, if this is the

431
00:19:56 --> 00:19:58
thing I'm looking for.


432
00:19:58 --> 00:20:05
And then, three: if not,
reduce to a smaller

433
00:20:05 --> 00:20:16
problem, and repeat.


434
00:20:16 --> 00:20:18
OK, you're going, yeah, come
on, that makes obvious sense.

435
00:20:18 --> 00:20:18
And it does.


436
00:20:18 --> 00:20:21
But I want you to keep that
template in mind, because we're

437
00:20:21 --> 00:20:22
going to come back to that.


438
00:20:22 --> 00:20:25
It's an example of a very
common tool that's going to be

439
00:20:25 --> 00:20:28
really useful to us, not just
for doing search, but for doing

440
00:20:28 --> 00:20:29
a whole range of problems.


441
00:20:29 --> 00:20:32
That is, in essence, the
template the describes

442
00:20:32 --> 00:20:34
a log style algorithm.


443
00:20:34 --> 00:20:37
And we're going to
come back to it.

444
00:20:37 --> 00:20:38
OK.


445
00:20:38 --> 00:20:41
With that in mind
though, didn't I cheat?

446
00:20:41 --> 00:20:45
I remind you, I know you're
not really listening

447
00:20:45 --> 00:20:45
to me, but that's OK.


448
00:20:45 --> 00:20:47
I reminded you at the beginning
of the lecture, I said, let's

449
00:20:47 --> 00:20:52
assume we have a sorted list,
and then let's go search it.

450
00:20:52 --> 00:20:52
Where in the world


451
00:20:52 --> 00:20:54
did that sorted list come from?


452
00:20:54 --> 00:20:58
What if I just get a list
of elements, what do I do?

453
00:20:58 --> 00:20:59
Well let's see.


454
00:20:59 --> 00:21:02
My fall back is, I could just
do linear search, walk down

455
00:21:02 --> 00:21:04
the list one at a time, just
comparing those things.

456
00:21:04 --> 00:21:04
OK.


457
00:21:04 --> 00:21:06
So that's sort of my base.


458
00:21:06 --> 00:21:08
But what if I wanted, you
know, how do I want to

459
00:21:08 --> 00:21:09
get to that sorted list?


460
00:21:09 --> 00:21:12
All right?


461
00:21:12 --> 00:21:16
Now.


462
00:21:16 --> 00:21:18
One of the questions, before we
get to doing the sorting, is

463
00:21:18 --> 00:21:20
even to ask, what should I do
in a search case like that?

464
00:21:20 --> 00:21:26
All right, so in particular,
does it make sense, if I'm

465
00:21:26 --> 00:21:30
given an unsorted list, to
first sort it, and

466
00:21:30 --> 00:21:31
then search it?


467
00:21:31 --> 00:21:34
Or should I just use the
basically linear case?

468
00:21:34 --> 00:21:34
All right?


469
00:21:34 --> 00:21:39
So, here's the question.


470
00:21:39 --> 00:21:47
Should we sort
before we search?

471
00:21:47 --> 00:21:47
OK.


472
00:21:47 --> 00:21:50
So let's see, if I'm going
to do this, how fast

473
00:21:50 --> 00:21:53
could we sort a list?


474
00:21:53 --> 00:22:05
Can we sort a list
in sublinear time?

475
00:22:05 --> 00:22:08
Sublinear meaning, something
like log less than linear time?

476
00:22:08 --> 00:22:11
What do you think?


477
00:22:11 --> 00:22:17
It's possible?


478
00:22:17 --> 00:22:19
Any thoughts?


479
00:22:19 --> 00:22:22
Don't you hate professors who
stand here waiting for you to

480
00:22:22 --> 00:22:25
answer, even when
they have candy?

481
00:22:25 --> 00:22:27
Does it make sense to
think we could do this in

482
00:22:27 --> 00:22:28
less than linear time?


483
00:22:28 --> 00:22:31
You know, it takes a
little bit of thinking.

484
00:22:31 --> 00:22:32
What would it mean--
[UNINTELLIGIBLE PHRASE]

485
00:22:32 --> 00:22:37
do I see a hand, way at
the back, yes please?

486
00:22:37 --> 00:22:39
Thank you.


487
00:22:39 --> 00:22:41
Man, you're going to really
make me work here, I have no

488
00:22:41 --> 00:22:43
idea if I can get it that
far, ah, your friend

489
00:22:43 --> 00:22:44
will help you out.


490
00:22:44 --> 00:22:45
Thank you.


491
00:22:45 --> 00:22:47
The gentleman has
it exactly right.

492
00:22:47 --> 00:22:49
How could I possibly do it in
sublinear time, I've got to

493
00:22:49 --> 00:22:52
look at least every
element once.

494
00:22:52 --> 00:22:54
And that's the kind of
instinct I'd like you to

495
00:22:54 --> 00:22:55
get into thinking about.


496
00:22:55 --> 00:22:58
So the answer here is no.


497
00:22:58 --> 00:23:00
OK.


498
00:23:00 --> 00:23:07
Can we sort it in linear time?


499
00:23:07 --> 00:23:07
Hmmm.


500
00:23:07 --> 00:23:11
That one's not so obvious.


501
00:23:11 --> 00:23:13
So let's think about
this for a second.

502
00:23:13 --> 00:23:18
To sort a list in linear time,
would say, I have to look at

503
00:23:18 --> 00:23:21
each element in the list
at most a constant

504
00:23:21 --> 00:23:21
number of times.


505
00:23:21 --> 00:23:23
It doesn't have to be
just once, right?

506
00:23:23 --> 00:23:25
It could be two or three times.


507
00:23:25 --> 00:23:25
Hmm.


508
00:23:25 --> 00:23:26
Well, wait a minute.


509
00:23:26 --> 00:23:28
If I want to sort a list, I'll
take one element, I've got to

510
00:23:28 --> 00:23:33
look at probably a lot of the
other elements in the list in

511
00:23:33 --> 00:23:35
order to decide where it goes.


512
00:23:35 --> 00:23:38
And that suggests it's going to
depend on how long the list is.

513
00:23:38 --> 00:23:41
All right, so that's a weak
argument, but in fact, it's

514
00:23:41 --> 00:23:49
a way of suggesting,
probably not.

515
00:23:49 --> 00:23:50
All right.


516
00:23:50 --> 00:23:52
So how fast could
I sort a list?

517
00:23:52 --> 00:23:54
How fast can we sort it?


518
00:23:54 --> 00:24:03
And we're going to come back to
this, probably next time if I

519
00:24:03 --> 00:24:12
time this right, but the answer
is, we can do it

520
00:24:12 --> 00:24:14
in n log n time.


521
00:24:14 --> 00:24:15
We're going to come
back to that.

522
00:24:15 --> 00:24:16
All right?


523
00:24:16 --> 00:24:18
And I'm going to say-- sort of
set that stage here, so that--

524
00:24:18 --> 00:24:21
It turns out that that's
probably about the best we can

525
00:24:21 --> 00:24:25
do, or again ends at the
length of the list.

526
00:24:25 --> 00:24:27
OK, so that's still comes
back to my question.

527
00:24:27 --> 00:24:30
If I want to search a list,
should I sort it first

528
00:24:30 --> 00:24:31
and then search it?


529
00:24:31 --> 00:24:33
Hmmm.


530
00:24:33 --> 00:24:39
OK, so let's do the comparison.


531
00:24:39 --> 00:24:41
I'm just going to take an
unsorted list and search

532
00:24:41 --> 00:24:43
it, I could do it in
linear time, right?

533
00:24:43 --> 00:24:44
One at a time.


534
00:24:44 --> 00:24:46
Walk down the elements
until I find it.

535
00:24:46 --> 00:24:48
That would be order n.


536
00:24:48 --> 00:24:53
On the other hand, if I want to
sort it first, OK, if I want to

537
00:24:53 --> 00:24:59
do sort and search, I want to
sort it, it's going to take n

538
00:24:59 --> 00:25:05
log n time to sort it, and
having done that, then I can

539
00:25:05 --> 00:25:09
search it in log n time.


540
00:25:09 --> 00:25:10
Ah.


541
00:25:10 --> 00:25:15
So which one's better?


542
00:25:15 --> 00:25:20
Yeah.


543
00:25:20 --> 00:25:20
Ah-ha.


544
00:25:20 --> 00:25:21
Thank you.


545
00:25:21 --> 00:25:23
Hold on to that thought
for second, I'm going

546
00:25:23 --> 00:25:23
to come back to it.


547
00:25:23 --> 00:25:25
That does not assume I'm
running a search it wants,

548
00:25:25 --> 00:25:29
which one's better?


549
00:25:29 --> 00:25:30
The unsorted, and you have
exactly the point I want to get

550
00:25:30 --> 00:25:33
to-- how come all the guys,
sorry, all the people

551
00:25:33 --> 00:25:36
answering questions are
way, way up in the back?

552
00:25:36 --> 00:25:40
Wow. that's a Tim Wakefield
pitch right there, all right.

553
00:25:40 --> 00:25:42
Thank you.


554
00:25:42 --> 00:25:43
He has it exactly right.


555
00:25:43 --> 00:25:45
OK?


556
00:25:45 --> 00:25:48
Is this smaller than that?


557
00:25:48 --> 00:25:49
No.


558
00:25:49 --> 00:25:50
Now that's a slight lie.


559
00:25:50 --> 00:25:52
Sorry, a slight
misstatement, OK?

560
00:25:52 --> 00:25:54
I could run for office,
couldn't I, if I can

561
00:25:54 --> 00:25:55
do that kind of talk.


562
00:25:55 --> 00:25:57
It's a slight misstatement in
the sense that these should

563
00:25:57 --> 00:25:58
really be orders of growth.


564
00:25:58 --> 00:26:00
There are some constants in
there, it depends on the size,

565
00:26:00 --> 00:26:05
but in general, n log n
has to be bigger than n.

566
00:26:05 --> 00:26:09
So, as the gentleman back there
said, if I'm searching it once,

567
00:26:09 --> 00:26:11
just use the linear search.


568
00:26:11 --> 00:26:15
On the other hand, am I likely
to only search a list once?

569
00:26:15 --> 00:26:16
Probably not.


570
00:26:16 --> 00:26:17
There are going to be multiple
elements I'm going to be

571
00:26:17 --> 00:26:21
looking for, so that suggests
that in fact, I want

572
00:26:21 --> 00:26:26
to amortize the cost.


573
00:26:26 --> 00:26:30
And what does that say?


574
00:26:30 --> 00:26:40
It says, let's assume I want
to do k searches of a list.

575
00:26:40 --> 00:26:41
OK.


576
00:26:41 --> 00:26:44
In the linear case, meaning in
the unsorted case, what's the

577
00:26:44 --> 00:26:48
complexity of this?
k times n, right?

578
00:26:48 --> 00:26:50
Order n to do the search, and
I've got to do it k times,

579
00:26:50 --> 00:26:55
so this would be k times n.


580
00:26:55 --> 00:26:58
In the [GARBLED PHRASE]


581
00:26:58 --> 00:27:03
sort and search case,
what's my cost?

582
00:27:03 --> 00:27:05
I've got to sort it, and we
said, and we'll come back to

583
00:27:05 --> 00:27:10
that next time, that I can do
the sort in n log n, and then

584
00:27:10 --> 00:27:13
what's the search in this case?


585
00:27:13 --> 00:27:17
Let's log n to do one search,
I want to do k of them,

586
00:27:17 --> 00:27:26
that's k log n, ah-ha!


587
00:27:26 --> 00:27:28
Now I'm in better shape, right?


588
00:27:28 --> 00:27:31
Especially for really large n
or for a lot of k, because now

589
00:27:31 --> 00:27:37
in general, this is going
to be smaller than that.

590
00:27:37 --> 00:27:40
So this is a place where
the amortized cost

591
00:27:40 --> 00:27:41
actually helps me out.


592
00:27:41 --> 00:27:43
And as the gentleman at the
back said, the question he

593
00:27:43 --> 00:27:46
asked is right, it depends
on what I'm trying to do.

594
00:27:46 --> 00:27:49
So when I do the analysis, I
want to think about what am I

595
00:27:49 --> 00:27:51
doing here, am I capturing
all the pieces of it?

596
00:27:51 --> 00:27:54
Here, the two variables that
matter are what's the length of

597
00:27:54 --> 00:27:57
the list, and how many times
I'm going to search it?

598
00:27:57 --> 00:28:01
So in this case, this one
wins, whereas in this

599
00:28:01 --> 00:28:07
case, that one wins.


600
00:28:07 --> 00:28:08
OK.


601
00:28:08 --> 00:28:13
Having said that, let's
look at doing some sorts.

602
00:28:13 --> 00:28:15
And I'm going to start
with a couple of dumb

603
00:28:15 --> 00:28:16
sorting mechanisms.


604
00:28:16 --> 00:28:19
Actually, that's the wrong way
saying it, they're simply

605
00:28:19 --> 00:28:21
brain-damaged, they're
not dumb, OK?

606
00:28:21 --> 00:28:23
They are computationally
challenged, meaning, at the

607
00:28:23 --> 00:28:25
time they were invented, they
were perfectly good sorting

608
00:28:25 --> 00:28:27
algorithms, there are better
ones, we're going to see a much

609
00:28:27 --> 00:28:29
better one next time around,
but this is a good way to just

610
00:28:29 --> 00:28:30
start thinking about how to
do the algorithm, or

611
00:28:30 --> 00:28:32
how to do the sort.


612
00:28:32 --> 00:28:33
Blah, try again.


613
00:28:33 --> 00:28:34
How to do this sort.


614
00:28:34 --> 00:28:37
So the first one I want to
talk about it's what's

615
00:28:37 --> 00:28:40
called selection sort.


616
00:28:40 --> 00:28:50
And it's on your handout, and
I'm going to bring the code up

617
00:28:50 --> 00:28:53
here, you can see it, it's
called cell sort, just

618
00:28:53 --> 00:28:54
for selection sort.


619
00:28:54 --> 00:28:59
And let's take a look
at what this does.

620
00:28:59 --> 00:28:59
OK.


621
00:28:59 --> 00:29:00
And in fact I think the
easy way to look at

622
00:29:00 --> 00:29:02
what this does-- boy.


623
00:29:02 --> 00:29:03
My jokes are that bad.


624
00:29:03 --> 00:29:04
Wow-- All right.


625
00:29:04 --> 00:29:07
I think the easiest way to look
at what this does, is let's

626
00:29:07 --> 00:29:12
take a really simple example--
I want to make sure I put the

627
00:29:12 --> 00:29:21
right things out-- I've got a
simple little list

628
00:29:21 --> 00:29:23
of values there.


629
00:29:23 --> 00:29:25
And if I look at this code, I'm
going to run over a loop, you

630
00:29:25 --> 00:29:29
can see that there, i is going
to go from zero up to the

631
00:29:29 --> 00:29:34
length minus 1, and I'm
going to keep track of

632
00:29:34 --> 00:29:35
a couple of variables.


633
00:29:35 --> 00:29:42
Min index, I think I
called it min val.

634
00:29:42 --> 00:29:42
OK.


635
00:29:42 --> 00:29:43
Let's simulate the code.


636
00:29:43 --> 00:29:44
Let's see what it's doing here.


637
00:29:44 --> 00:29:47
All right, so we start off.


638
00:29:47 --> 00:29:53
Initially i-- ah, let me do it
this way, i is going to point

639
00:29:53 --> 00:29:58
there, and I want to make sure
I do it right, OK-- and min

640
00:29:58 --> 00:30:03
index is going to point to the
value of i, which is there,

641
00:30:03 --> 00:30:06
and min value is initially
going to have the value 1.

642
00:30:06 --> 00:30:09
So we're simply catting a
hold of what's the first

643
00:30:09 --> 00:30:10
value we've got there.


644
00:30:10 --> 00:30:12
And then what do we do?


645
00:30:12 --> 00:30:18
We start with j pointing here,
and we can see what this loop's

646
00:30:18 --> 00:30:20
going to do, right? j is
just going to move up.

647
00:30:20 --> 00:30:23
So it's going to look at the
rest of the list, walking

648
00:30:23 --> 00:30:25
along, and what does it do?


649
00:30:25 --> 00:30:27
It says, right.


650
00:30:27 --> 00:30:30
If j is-- well it says until j
is at the less than the length

651
00:30:30 --> 00:30:37
of l-- it says, if min value is
bigger than the thing I'm

652
00:30:37 --> 00:30:39
looking at, I'm going to
do something, all right?

653
00:30:39 --> 00:30:40
So let's walk this.


654
00:30:40 --> 00:30:42
Min value is 1,.


655
00:30:42 --> 00:30:43
Is 1 bigger than 8?


656
00:30:43 --> 00:30:43
No.


657
00:30:43 --> 00:30:44
I move j up.


658
00:30:44 --> 00:30:44
Is 1 bigger than 3?


659
00:30:44 --> 00:30:45
No.


660
00:30:45 --> 00:30:46
1 bigger than 6?


661
00:30:46 --> 00:30:46
No.


662
00:30:46 --> 00:30:47
1 bigger than 4?


663
00:30:47 --> 00:30:47
No.


664
00:30:47 --> 00:30:50
I get to the end of the loop,
and I actually do a little

665
00:30:50 --> 00:30:51
bit of wasted motion there.


666
00:30:51 --> 00:30:55
And the little bit of wasted
motion is, I take the value at

667
00:30:55 --> 00:31:00
i, store it away temporarily,
take the value where min index

668
00:31:00 --> 00:31:04
is pointing to, put it back in
there, and then swap it around.

669
00:31:04 --> 00:31:05
OK.


670
00:31:05 --> 00:31:11
Having done that, let's move
i up to here. i is now

671
00:31:11 --> 00:31:12
pointing at that thing.


672
00:31:12 --> 00:31:13
Go through the second
round of the loop.

673
00:31:13 --> 00:31:14
OK.


674
00:31:14 --> 00:31:15
What does that say?


675
00:31:15 --> 00:31:21
I'm going to change min index
to also point there n value is

676
00:31:21 --> 00:31:26
8, j starts off here, and I
say, OK, is the thing

677
00:31:26 --> 00:31:30
I'm looking at here
smaller than that?

678
00:31:30 --> 00:31:31
Yes.


679
00:31:31 --> 00:31:32
Ah-ha.


680
00:31:32 --> 00:31:33
What does that say to do?


681
00:31:33 --> 00:31:44
It says, gee, make min index
point to there, min value be 3.

682
00:31:44 --> 00:31:46
Change j.


683
00:31:46 --> 00:31:47
Is 6 bigger than 3?


684
00:31:47 --> 00:31:48
Yes.


685
00:31:48 --> 00:31:49
Is 4 bigger than 3?


686
00:31:49 --> 00:31:50
Yes.


687
00:31:50 --> 00:31:51
Get to the end.


688
00:31:51 --> 00:31:55
And when I get to the
end, what do I do?

689
00:31:55 --> 00:32:01
Well, you see, I say, take
temp, and store away

690
00:32:01 --> 00:32:04
what's here, all right?


691
00:32:04 --> 00:32:07
Which is that value, and then
take what min index is pointing

692
00:32:07 --> 00:32:21
to, and stick it in there, and
finally, replace that value.

693
00:32:21 --> 00:32:23
OK.


694
00:32:23 --> 00:32:24
Aren't you glad I'm
not a computer?

695
00:32:24 --> 00:32:26
Slow as hell.


696
00:32:26 --> 00:32:29
What's this thing doing?


697
00:32:29 --> 00:32:34
It's walking along the list,
looking for the smallest thing

698
00:32:34 --> 00:32:37
in the back end of the list,
keeping track of where it came

699
00:32:37 --> 00:32:41
from, and swapping it with
that spot in the list.

700
00:32:41 --> 00:32:42
All right?


701
00:32:42 --> 00:32:45
So in the first case, I didn't
have to do any swaps because

702
00:32:45 --> 00:32:46
1 was the smallest thing.


703
00:32:46 --> 00:32:49
In the second case, I found in
the next smallest element and

704
00:32:49 --> 00:32:52
moved here, taking what was
there and moving it on, in this

705
00:32:52 --> 00:32:56
case I would swap the 4 and the
8, and in next case I wouldn't

706
00:32:56 --> 00:32:58
have to do anything.


707
00:32:58 --> 00:32:59
Let's check it out.


708
00:32:59 --> 00:33:03
I've written a little bit of a
test script here, so if we test

709
00:33:03 --> 00:33:07
cell sort, and I've written
this so that it's going to

710
00:33:07 --> 00:33:13
print out what the list is at
the end of each round, OK.

711
00:33:13 --> 00:33:16
Ah-ha.


712
00:33:16 --> 00:33:17
Notice what-- where am
I, here-- notice what

713
00:33:17 --> 00:33:19
happened in this case.


714
00:33:19 --> 00:33:22
At the end of the first
round, I've got the smallest

715
00:33:22 --> 00:33:23
element at the front.


716
00:33:23 --> 00:33:25
At the end of the second round,
I've got the smallest two

717
00:33:25 --> 00:33:29
elements at the front, in fact
I got all of them sorted out.

718
00:33:29 --> 00:33:31
And it actually runs through
the loop multiple times,

719
00:33:31 --> 00:33:33
making sure that it's
in the right form.

720
00:33:33 --> 00:33:36
Let's take another example.


721
00:33:36 --> 00:33:39
OK.


722
00:33:39 --> 00:33:40
Smallest element at the front.


723
00:33:40 --> 00:33:42
Smallest two elements
at the front.

724
00:33:42 --> 00:33:44
Smallest three elements
at the front.

725
00:33:44 --> 00:33:46
Smallest four elements at the
front, you get the idea.

726
00:33:46 --> 00:33:49
Smallest five elements
at the front.

727
00:33:49 --> 00:33:52
So this is a nice little
search-- sorry, a nice

728
00:33:52 --> 00:33:53
little sort algorithm .


729
00:33:53 --> 00:33:56
And in fact, it's relying on
something that we're going to

730
00:33:56 --> 00:33:59
come back to, called
the loop invariant.

731
00:33:59 --> 00:34:16
Actually, let me put it on
this board so you can see it.

732
00:34:16 --> 00:34:18
The loop invariant what does
the loop invariant mean?

733
00:34:18 --> 00:34:21
It says, here is a property
that is true of this structure

734
00:34:21 --> 00:34:23
every time through the loop.


735
00:34:23 --> 00:34:26
In the loop invariant here is
the following: the list is

736
00:34:26 --> 00:34:37
split, into a prefix or a first
part, and a suffix, the prefix

737
00:34:37 --> 00:34:48
is sorted, the suffix is not,
and basically, the loop starts

738
00:34:48 --> 00:34:51
off with the prefix being
nothing and it keeps increasing

739
00:34:51 --> 00:34:53
the size of the prefix by 1
until it gets through the

740
00:34:53 --> 00:34:56
entire list, at which point
there's nothing in the suffix

741
00:34:56 --> 00:35:00
and entire prefix is sorted.


742
00:35:00 --> 00:35:01
OK?


743
00:35:01 --> 00:35:04
So you can see that, it's just
walking through it, and in fact

744
00:35:04 --> 00:35:06
if I look at a couple of
another-- another couple of

745
00:35:06 --> 00:35:09
examples, it's been a long day,
again, you can see

746
00:35:09 --> 00:35:12
that property.


747
00:35:12 --> 00:35:16
You'll also notice that this
thing goes through the entire

748
00:35:16 --> 00:35:19
list, even if the list is
sorted before it gets

749
00:35:19 --> 00:35:20
partway through.


750
00:35:20 --> 00:35:23
And that you might look at, for
example, that first example,

751
00:35:23 --> 00:35:26
and say, man by this stage it
was already sorted, yet it had

752
00:35:26 --> 00:35:28
to go through and check that
the third element was in

753
00:35:28 --> 00:35:30
the right place, and then
the fourth and then the

754
00:35:30 --> 00:35:32
fifth and then the six.


755
00:35:32 --> 00:35:34
OK.


756
00:35:34 --> 00:35:35
What order of growth?


757
00:35:35 --> 00:35:40
What's complexity of this?


758
00:35:40 --> 00:35:43
I've got to get rid
of this candy.

759
00:35:43 --> 00:35:44
Anybody help me out?


760
00:35:44 --> 00:35:46
What's the complexity of this?


761
00:35:46 --> 00:35:49
Sorry, somebody at the back.


762
00:35:49 --> 00:35:49
n squared.


763
00:35:49 --> 00:35:52
Yeah, where n is what?


764
00:35:52 --> 00:35:54
Yeah, and I can't even
see who's saying that.

765
00:35:54 --> 00:35:56
Thank you.


766
00:35:56 --> 00:35:57
Sorry, I've got the wrong
glasses on, but you're

767
00:35:57 --> 00:35:59
absolutely right, and in
case the rest of you

768
00:35:59 --> 00:36:03
didn't hear it, n squared.


769
00:36:03 --> 00:36:05
How do I figure that out?


770
00:36:05 --> 00:36:09
Well I'm looping down
the list, right?

771
00:36:09 --> 00:36:11
I'm walking down the list.


772
00:36:11 --> 00:36:12
So it's certainly at
least linear in the

773
00:36:12 --> 00:36:13
length of the list.


774
00:36:13 --> 00:36:15
For each starting
point, what do I do?

775
00:36:15 --> 00:36:19
I look at the rest of the list
to decide what's the element

776
00:36:19 --> 00:36:21
to swap into the next place.


777
00:36:21 --> 00:36:23
Now, you might say,
well, wait a minute.

778
00:36:23 --> 00:36:26
As I keep moving down, that
part gets smaller, it's not

779
00:36:26 --> 00:36:29
always the initial length of
the list, and you're right.

780
00:36:29 --> 00:36:31
But if you do the sums, or if
you want to think of it this

781
00:36:31 --> 00:36:34
way, if you think about this
more generally, it's always on

782
00:36:34 --> 00:36:36
average at least the
length of the list.

783
00:36:36 --> 00:36:39
So I've got to do
n things n times.

784
00:36:39 --> 00:36:42
So it's quadratic, in
terms of that sort.

785
00:36:42 --> 00:36:43
OK.


786
00:36:43 --> 00:36:45
That's one way to do this sort.


787
00:36:45 --> 00:36:50
Let's do another one.


788
00:36:50 --> 00:36:52
The second one we're going to
do is called bubble sort.

789
00:36:52 --> 00:36:55
All right?


790
00:36:55 --> 00:36:59
And bubble sort is
also on your handout.

791
00:36:59 --> 00:37:08
And you want to take the first
of these, let me-- sorry, for a

792
00:37:08 --> 00:37:11
second let me uncomment that,
and let me comment this out--

793
00:37:11 --> 00:37:19
All right, you can see the
code for bubble sort there.

794
00:37:19 --> 00:37:21
Let's just look at it for a
second, then we'll try some

795
00:37:21 --> 00:37:25
examples, and then we'll figure
out what it's actually doing.

796
00:37:25 --> 00:37:27
So bubble sort, which
is right up here.

797
00:37:27 --> 00:37:28
What's it going to do?


798
00:37:28 --> 00:37:32
It's going to let j run over
the length of the list, all

799
00:37:32 --> 00:37:34
right, so it's going to start
at some point to move down, and

800
00:37:34 --> 00:37:39
then it's going to let i run
over range, that's just one

801
00:37:39 --> 00:37:43
smaller, and what's
it doing there?

802
00:37:43 --> 00:37:45
It's looking at
successive pairs, right?

803
00:37:45 --> 00:37:48
It's looking at the i'th and
the i plus first element, and

804
00:37:48 --> 00:37:51
it's saying, gee, if the i'th
element is bigger than the i'th

805
00:37:51 --> 00:37:55
plus first element, what's the
next set of three things doing?

806
00:37:55 --> 00:37:57
Just swapping them, right?


807
00:37:57 --> 00:38:00
I temporarily hold on to what's
in the i'th element so I can

808
00:38:00 --> 00:38:02
move the i plus first one
in, and then replace that

809
00:38:02 --> 00:38:05
with the i'th element.


810
00:38:05 --> 00:38:06
OK.


811
00:38:06 --> 00:38:08
What's this thing doing
then, in terms of sorting?

812
00:38:08 --> 00:38:13
At the end of the first pass,
what could I say about

813
00:38:13 --> 00:38:16
the result of this thing?


814
00:38:16 --> 00:38:25
What's the last element
in the list look like?

815
00:38:25 --> 00:38:28
I hate professors who do this.


816
00:38:28 --> 00:38:30
Well, let's try it.


817
00:38:30 --> 00:38:33
Let's try a little test.


818
00:38:33 --> 00:38:35
OK?


819
00:38:35 --> 00:38:40
Test bubble sort-- especially
if I could type-- let's

820
00:38:40 --> 00:38:44
run it on the first list.


821
00:38:44 --> 00:38:49
OK, let's try it
on another one.

822
00:38:49 --> 00:38:50
Oops sorry.


823
00:38:50 --> 00:38:53
Ah, I didn't want to do it
this time, I forgot to do

824
00:38:53 --> 00:38:56
the following, bear with me.


825
00:38:56 --> 00:38:57
I gave away my punchline.


826
00:38:57 --> 00:38:58
Let's try it again.


827
00:38:58 --> 00:39:04
Test bubble sort.


828
00:39:04 --> 00:39:07
OK, there's the first run, I'm
going to take a different list.

829
00:39:07 --> 00:39:18
Can you see a pattern there?


830
00:39:18 --> 00:39:18
Yeah.


831
00:39:18 --> 00:39:21
STUDENT: The last cell
in the list is always

832
00:39:21 --> 00:39:22
going to [INAUDIBLE]


833
00:39:22 --> 00:39:23
PROFESSOR ERIC GRIMSON: Yeah.


834
00:39:23 --> 00:39:23
Why?


835
00:39:23 --> 00:39:24
You're right, but why?


836
00:39:24 --> 00:39:28
STUDENT:
[UNINTELLIGIBLE PHRASE]

837
00:39:28 --> 00:39:29
PROFESSOR ERIC GRIMSON:
Exactly right.

838
00:39:29 --> 00:39:30
Thank you.


839
00:39:30 --> 00:39:37
The observation is, thank you,
on the first pass through, the

840
00:39:37 --> 00:39:39
last element is the biggest
thing in the list.

841
00:39:39 --> 00:39:42
On the next pass through, the
next largest element is at the

842
00:39:42 --> 00:39:43
second point in the list.


843
00:39:43 --> 00:39:43
OK?


844
00:39:43 --> 00:39:45
Because what am I doing?


845
00:39:45 --> 00:39:46
It's called bubble sort
because it's literally

846
00:39:46 --> 00:39:47
bubbling along, right?


847
00:39:47 --> 00:39:51
I'm walking along the list
once, taking two things,

848
00:39:51 --> 00:39:53
and saying, make sure
the biggest one is next.

849
00:39:53 --> 00:39:56
So wherever the largest element
started out in the list, by

850
00:39:56 --> 00:39:59
the time I get through
it, it's at the end.

851
00:39:59 --> 00:40:03
And then I go back and I start
again, and I do the same thing.

852
00:40:03 --> 00:40:03
OK.


853
00:40:03 --> 00:40:06
The next largest element has to
end up in the second last spot.

854
00:40:06 --> 00:40:07
Et cetera.


855
00:40:07 --> 00:40:09
All right, so it's called
bubble sort because it

856
00:40:09 --> 00:40:12
does this bubbling up
until it gets there.

857
00:40:12 --> 00:40:14
Now.


858
00:40:14 --> 00:40:15
What's the order
of growth here?

859
00:40:15 --> 00:40:19
What's the complexity?


860
00:40:19 --> 00:40:21
I haven't talked to the side
of the room in a while,

861
00:40:21 --> 00:40:22
actually I have.


862
00:40:22 --> 00:40:23
This gentleman has
helped me out.

863
00:40:23 --> 00:40:23
Somebody else help me out.


864
00:40:23 --> 00:40:27
What's the complexity here?


865
00:40:27 --> 00:40:31
I must have the wrong
glasses on to see a hand.

866
00:40:31 --> 00:40:34
No help.


867
00:40:34 --> 00:40:36
Log?


868
00:40:36 --> 00:40:38
Linear?


869
00:40:38 --> 00:40:40
Exponential?


870
00:40:40 --> 00:40:41
Quadratic?


871
00:40:41 --> 00:40:43
Yeah.


872
00:40:43 --> 00:40:44
Log.


873
00:40:44 --> 00:40:50
It's a good think, but why
do you think it's log?

874
00:40:50 --> 00:40:50
Ah-ha.


875
00:40:50 --> 00:40:53
It's not a bad instinct, the
length is getting shorter each

876
00:40:53 --> 00:40:55
time, but what's one of the
characteristics of

877
00:40:55 --> 00:40:56
a log algorithm?


878
00:40:56 --> 00:40:58
It drops in half each time.


879
00:40:58 --> 00:41:00
So this isn't--


880
00:41:00 --> 00:41:01
OK.


881
00:41:01 --> 00:41:02
And you're also close.


882
00:41:02 --> 00:41:04
It's going to be linear,
but how many times do

883
00:41:04 --> 00:41:05
I go through this?


884
00:41:05 --> 00:41:08
All right, I've got to do
one pass to bubble the

885
00:41:08 --> 00:41:10
last element to the end.


886
00:41:10 --> 00:41:12
I've got to do another
pass to bubble the second

887
00:41:12 --> 00:41:12
last element to the end.


888
00:41:12 --> 00:41:14
I've got to do another pass.


889
00:41:14 --> 00:41:15
Huh.


890
00:41:15 --> 00:41:18
Sounds like a linear number
of times I've got to

891
00:41:18 --> 00:41:20
do-- oh fudge knuckle.


892
00:41:20 --> 00:41:23
A linear number of
things, quadratic.

893
00:41:23 --> 00:41:25
Right?


894
00:41:25 --> 00:41:25
OK.


895
00:41:25 --> 00:41:32
So this is again an example,
this was quadratic, and

896
00:41:32 --> 00:41:35
this one was quadratic.


897
00:41:35 --> 00:41:40
And I have this, to write it
out, this is order the length

898
00:41:40 --> 00:41:43
of the list squared, OK?


899
00:41:43 --> 00:41:48
Just to make it clear what
we're actually measuring there.

900
00:41:48 --> 00:41:48
All


901
00:41:48 --> 00:41:48
right.


902
00:41:48 --> 00:41:50
Could we do better?


903
00:41:50 --> 00:41:52
Sure.


904
00:41:52 --> 00:41:54
And in fact, next time we're
going to show you that n log n

905
00:41:54 --> 00:41:57
algorithm, but even with bubble
sort, we can do better.

906
00:41:57 --> 00:42:00
In a particular, if I look at
those traces, I can certainly

907
00:42:00 --> 00:42:04
see cases where, man, I already
had the list sorted much

908
00:42:04 --> 00:42:06
earlier on, and yet I kept
going back to see if there was

909
00:42:06 --> 00:42:08
anything else to bubble up.


910
00:42:08 --> 00:42:09
How would I keep track of that?


911
00:42:09 --> 00:42:12
Could I take advantage of that?


912
00:42:12 --> 00:42:13
Sure.


913
00:42:13 --> 00:42:17
Why don't I just keep track on
each pass through the algorithm

914
00:42:17 --> 00:42:18
whether I have done any swaps?


915
00:42:18 --> 00:42:20
All right?


916
00:42:20 --> 00:42:22
Because if I don't do any
swaps on a pass through

917
00:42:22 --> 00:42:23
the algorithm, then
it says everything's

918
00:42:23 --> 00:42:24
in the right order.


919
00:42:24 --> 00:42:28
And so, in fact, the version
that I commented out-- which is

920
00:42:28 --> 00:42:30
also in your handout and I'm
now going to uncomment, let's

921
00:42:30 --> 00:42:38
get that one out, get rid of
this one-- notice

922
00:42:38 --> 00:42:39
the only change.


923
00:42:39 --> 00:42:42
I'm going to keep track of a
little variable called swap,

924
00:42:42 --> 00:42:46
it's initially true, and as
long as it's true, I'm going to

925
00:42:46 --> 00:42:49
keep going, but inside of the
loop I'm going to set it to

926
00:42:49 --> 00:42:53
false, and only if I do a
swap will I set it to true.

927
00:42:53 --> 00:42:55
This says, if I go through
an entire pass through

928
00:42:55 --> 00:42:58
the list and nothing
gets changed, I'm done.

929
00:42:58 --> 00:43:09
And in fact if I do that, and
try test bubble sort, well, in

930
00:43:09 --> 00:43:13
the first case, looks the same.


931
00:43:13 --> 00:43:13
Ah.


932
00:43:13 --> 00:43:17
On the second case, I
spot it right away.

933
00:43:17 --> 00:43:20
On the third case, it takes
me the same amount of time.

934
00:43:20 --> 00:43:24
And the fourth case, when
I set it up, I'm done.

935
00:43:24 --> 00:43:24
OK.


936
00:43:24 --> 00:43:25
So what's the lesson here?


937
00:43:25 --> 00:43:28
I can be a little more careful
about keeping track of what

938
00:43:28 --> 00:43:30
goes on inside of that loop.


939
00:43:30 --> 00:43:31
If I don't have any more work
to do, let me just stop.

940
00:43:31 --> 00:43:33
All right.


941
00:43:33 --> 00:43:36
Nonetheless, even with this
change, what's the order

942
00:43:36 --> 00:43:39
growth for bubble sort?


943
00:43:39 --> 00:43:40
Still quadratic, right?


944
00:43:40 --> 00:43:42
I'm looking for the worst case
behavior, it's still quadratic,

945
00:43:42 --> 00:43:44
it's quadratic in the length of
the list, so I'm sort

946
00:43:44 --> 00:43:47
of stuck with that.


947
00:43:47 --> 00:43:47
Now.


948
00:43:47 --> 00:43:49
Let me ask you one last
question, and then

949
00:43:49 --> 00:43:51
we'll wrap this up.


950
00:43:51 --> 00:43:55
Which of these
algorithms is better?

951
00:43:55 --> 00:43:57
Insertion sort or bubble sort?


952
00:43:57 --> 00:43:59
STUDENT: Bubble.


953
00:43:59 --> 00:43:59
PROFESSOR ERIC GRIMSON: Bubble.


954
00:43:59 --> 00:44:00
Bubble bubble toil and trouble.


955
00:44:00 --> 00:44:01
Who said bubble?


956
00:44:01 --> 00:44:02
Why?


957
00:44:02 --> 00:44:04
STUDENT: Well, the first
one was too inefficient

958
00:44:04 --> 00:44:05
[UNINTELLIGIBLE]


959
00:44:05 --> 00:44:15
store and compare each
one, so [UNINTELLIGIBLE]

960
00:44:15 --> 00:44:16
PROFESSOR ERIC GRIMSON:
It's not a bad instinct.

961
00:44:16 --> 00:44:16
Right.


962
00:44:16 --> 00:44:19
So it-- so, your argument is,
bubble is better because it's

963
00:44:19 --> 00:44:23
is essentially not doing all
these extra comparisons.

964
00:44:23 --> 00:44:25
Another way of saying it
is, I can do this stop

965
00:44:25 --> 00:44:25
when I don't need to.


966
00:44:25 --> 00:44:26
All right?


967
00:44:26 --> 00:44:28
OK.


968
00:44:28 --> 00:44:30
Anybody have an
opposing opinion?

969
00:44:30 --> 00:44:34
Wow, this sounds like a
presidential debate.

970
00:44:34 --> 00:44:35
Sorry, I should reward you.


971
00:44:35 --> 00:44:37
Thank you for that statement.


972
00:44:37 --> 00:44:40
Anybody have an
opposing opinion?

973
00:44:40 --> 00:44:41
Everybody's answering
these things and sitting

974
00:44:41 --> 00:44:42
way up at the back.


975
00:44:42 --> 00:44:44
Nice catch.


976
00:44:44 --> 00:44:44
Yeah.


977
00:44:44 --> 00:44:55
STUDENT: [INAUDIBLE]


978
00:44:55 --> 00:44:55
PROFESSOR ERIC GRIMSON: I
don't think so, right?

979
00:44:55 --> 00:44:58
I think selection sort, I still
have to go through multiple

980
00:44:58 --> 00:45:02
times, it was still quadratic,
OK, but I think you're heading

981
00:45:02 --> 00:45:04
towards a direction I want to
get at, so let me prime

982
00:45:04 --> 00:45:05
this a little bit.


983
00:45:05 --> 00:45:10
How many swaps do I do in
general in bubble sort,

984
00:45:10 --> 00:45:13
compared to selection source?


985
00:45:13 --> 00:45:14
God bless.


986
00:45:14 --> 00:45:18
Oh, sorry, that wasn't a
sneeze, it was a two?

987
00:45:18 --> 00:45:23
How many swaps do I
do in bubble sort?

988
00:45:23 --> 00:45:24
A lot.


989
00:45:24 --> 00:45:24
Right.


990
00:45:24 --> 00:45:27
Potentially a lot because I'm
constantly doing that, that

991
00:45:27 --> 00:45:29
says I'm running that inner
loop a whole bunch of times.

992
00:45:29 --> 00:45:34
How many swaps do I do
in selection sort?

993
00:45:34 --> 00:45:36
Once each time.


994
00:45:36 --> 00:45:36
Right?


995
00:45:36 --> 00:45:39
I only do one swap potentially,
it-- though not one

996
00:45:39 --> 00:45:42
potentially, each time at the
end of the loop I do a swap.

997
00:45:42 --> 00:45:45
So this actually suggests
again, the orders of growth

998
00:45:45 --> 00:45:49
are the same, but probably
selection sort is a more

999
00:45:49 --> 00:45:51
efficient algorithm, because
I'm not doing that

1000
00:45:51 --> 00:45:53
constant amount of work
every time around.

1001
00:45:53 --> 00:45:55
And in fact, if you go look
up, you won't see bubble

1002
00:45:55 --> 00:45:56
sort used very much.


1003
00:45:56 --> 00:45:59
Most-- I shouldn't say most,
many computer scientists don't

1004
00:45:59 --> 00:46:00
think it should be taught,
because it's just

1005
00:46:00 --> 00:46:01
so inefficient.


1006
00:46:01 --> 00:46:03
I disagree, because it's a
clever idea, but it's still

1007
00:46:03 --> 00:46:06
something that we have
to keep track of.

1008
00:46:06 --> 00:46:07
All right.


1009
00:46:07 --> 00:46:10
We haven't gotten to our n log
n algorithm, we're going to do

1010
00:46:10 --> 00:46:13
that next time, but I want
to set the stage here by

1011
00:46:13 --> 00:46:16
pulling out one last piece.


1012
00:46:16 --> 00:46:17
OK.


1013
00:46:17 --> 00:46:19
Could we do better in
terms of sorting?

1014
00:46:19 --> 00:46:20
Again, remember
what our goal was.

1015
00:46:20 --> 00:46:23
If we could do sort, then we
saw, if we amortized the cost,

1016
00:46:23 --> 00:46:25
that searching is a lot
more efficient if we're

1017
00:46:25 --> 00:46:27
searching a sorted list.


1018
00:46:27 --> 00:46:29
How could we do better?


1019
00:46:29 --> 00:46:30
Let me set the stage.


1020
00:46:30 --> 00:46:34
I already said, back here, when
I used this board, that this

1021
00:46:34 --> 00:46:36
idea was really important.


1022
00:46:36 --> 00:46:43
And that's because that
is a version of a divide

1023
00:46:43 --> 00:46:48
and conquer algorithm.


1024
00:46:48 --> 00:46:48
OK.


1025
00:46:48 --> 00:46:51
Binary search is perhaps the
simplest of the divide and

1026
00:46:51 --> 00:46:53
conquer algorithms, and
what does that mean?

1027
00:46:53 --> 00:46:56
It says, in order to solve a
problem, cut it down to a

1028
00:46:56 --> 00:46:58
smaller problem and try
and solve that one.

1029
00:46:58 --> 00:47:01
So to just preface what we're
going to do next time, what

1030
00:47:01 --> 00:47:04
would happen if I wanted to do
sort, and rather than in

1031
00:47:04 --> 00:47:09
sorting the entire list at
once, I broke it into pieces,

1032
00:47:09 --> 00:47:12
and sorted the pieces, and then
just figured out a very

1033
00:47:12 --> 00:47:14
efficient way to bring those
two pieces and merge them

1034
00:47:14 --> 00:47:16
back together again?


1035
00:47:16 --> 00:47:19
Where those pieces, I would do
the same thing with, I would

1036
00:47:19 --> 00:47:23
divide them up into smaller
chunks, and sort those.

1037
00:47:23 --> 00:47:25
Is that going to give me a
more efficient algorithm?

1038
00:47:25 --> 00:47:27
And if you come back
on Thursday, we'll

1039
00:47:27 --> 00:47:29
answer that question.


1040
00:47:29 --> 00:47:29




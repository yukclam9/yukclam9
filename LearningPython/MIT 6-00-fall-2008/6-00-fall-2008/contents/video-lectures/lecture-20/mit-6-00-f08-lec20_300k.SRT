1
00:00:00 --> 00:00:00



2
00:00:00 --> 00:00:02
The following
content is provided under a

3
00:00:02 --> 00:00:03
Creative Commons license.


4
00:00:03 --> 00:00:06
Your support will help MIT
OpenCourseWare continue to

5
00:00:06 --> 00:00:10
offer high quality educational
resources for free.

6
00:00:10 --> 00:00:13
To make a donation, or view
additional material from

7
00:00:13 --> 00:00:17
hundreds of MIT courses,
visit MIT OpenCourseWare

8
00:00:17 --> 00:00:19
at ocw.mit.edu.


9
00:00:19 --> 00:00:25
PROFESSOR: All right, so today
we're returning to simulations.

10
00:00:25 --> 00:00:30
And I'm going to do at first, a
little bit more abstractly, and

11
00:00:30 --> 00:00:32
then come back to some details.


12
00:00:32 --> 00:00:38
So they're different ways to
classify simulation models.

13
00:00:38 --> 00:00:53
The first is whether it's
stochastic or deterministic.

14
00:00:53 --> 00:00:57
And the difference here is in a
deterministic simulation, you

15
00:00:57 --> 00:01:04
should get the same result
every time you run it.

16
00:01:04 --> 00:01:06
And there's a lot of
uses we'll see for

17
00:01:06 --> 00:01:08
deterministic simulations.


18
00:01:08 --> 00:01:14
And then there's stochastic
simulations, where the answer

19
00:01:14 --> 00:01:17
will differ from run to run
because there's an element

20
00:01:17 --> 00:01:20
of randomness in it.


21
00:01:20 --> 00:01:23
So here if you run it again and
again you get the same outcome

22
00:01:23 --> 00:01:29
every time, here you may not.


23
00:01:29 --> 00:01:35
So, for example, the problem
set that's due today --

24
00:01:35 --> 00:01:40
is that a stochastic or
deterministic simulation?

25
00:01:40 --> 00:01:42
Somebody?


26
00:01:42 --> 00:01:45
Stochastic, exactly.


27
00:01:45 --> 00:01:49
And that's what we're going to
focus on in this class, because

28
00:01:49 --> 00:01:51
one of the interesting
questions we'll see about

29
00:01:51 --> 00:01:58
stochastic simulations is, how
often do have to run them

30
00:01:58 --> 00:02:00
before you believe the answer?


31
00:02:00 --> 00:02:03
And that turns out to be
a very important issue.

32
00:02:03 --> 00:02:05
You run it once, you get
an answer, you can't

33
00:02:05 --> 00:02:07
take it to the bank.


34
00:02:07 --> 00:02:09
Because the next time you run
it, you may get a completely

35
00:02:09 --> 00:02:11
different answer.


36
00:02:11 --> 00:02:14
So that will get us a little
bit into the whole issue

37
00:02:14 --> 00:02:19
of statistical analysis.


38
00:02:19 --> 00:02:31
Another interesting dichotomy
is static vs dynamic.

39
00:02:31 --> 00:02:35
We'll look at both, but
will spend more time

40
00:02:35 --> 00:02:37
on dynamic models.


41
00:02:37 --> 00:02:43
So the issue --
it's not my phone.

42
00:02:43 --> 00:02:45
If it's your mother, you
could feel free to take it,

43
00:02:45 --> 00:02:50
otherwise -- OK, no problem.


44
00:02:50 --> 00:02:54
Inevitable.


45
00:02:54 --> 00:02:57
In a dynamic situation,
time plays a role.

46
00:02:57 --> 00:03:00
And you look at how
things evolve over time.

47
00:03:00 --> 00:03:07
In a static simulation, there
is no issue with time.

48
00:03:07 --> 00:03:11
We'll be looking at both, but
most of the time we'll be

49
00:03:11 --> 00:03:15
focusing on dynamic ones.


50
00:03:15 --> 00:03:19
So an example of this
kind of thing would be a

51
00:03:19 --> 00:03:24
queuing network model.


52
00:03:24 --> 00:03:27
This is one of the most popular
and important kinds of

53
00:03:27 --> 00:03:31
dynamic simulations.


54
00:03:31 --> 00:03:36
Where you try and look at how
queues, a fancy word for

55
00:03:36 --> 00:03:40
lines, evolve over time.


56
00:03:40 --> 00:03:44
So for example, people who are
trying to decide how many lanes

57
00:03:44 --> 00:03:48
should be in a highway, or how
far apart the exits should be,

58
00:03:48 --> 00:03:52
or what should the ratio of
Fast Lane tolls to manually

59
00:03:52 --> 00:03:54
staffed tolls should be.


60
00:03:54 --> 00:04:00
All use queuing networks to
try and answer that question.

61
00:04:00 --> 00:04:02
And we'll look at some examples
of these later because

62
00:04:02 --> 00:04:04
they are very important.


63
00:04:04 --> 00:04:10
Particularly for things related
to scheduling and planning.

64
00:04:10 --> 00:04:26
A third dichotomy is
discrete vs continuous.

65
00:04:26 --> 00:04:31
Imagine, for example, trying
to analyze the flow of

66
00:04:31 --> 00:04:35
traffic along the highway.


67
00:04:35 --> 00:04:39
One way to do it, is to
try and have a simulation

68
00:04:39 --> 00:04:43
which models each vehicle.


69
00:04:43 --> 00:04:45
That would be a discrete
simulation, because you've

70
00:04:45 --> 00:04:47
got different parts.


71
00:04:47 --> 00:04:53
Alternatively, you might decide
to treat traffic as a flow,

72
00:04:53 --> 00:04:57
kind of like water flowing
through things, where changes

73
00:04:57 --> 00:05:01
in the flow can be described
by differential equations.

74
00:05:01 --> 00:05:08
That would lead to a
continuous model.

75
00:05:08 --> 00:05:13
Another example is, a lot of
effort has gone into analyzing

76
00:05:13 --> 00:05:18
the way blood flows
through the human body.

77
00:05:18 --> 00:05:22
You can try and model it
discretely, where you take each

78
00:05:22 --> 00:05:27
red blood cell, each white
blood cell, and look at how

79
00:05:27 --> 00:05:30
they move, or simulate
how they move.

80
00:05:30 --> 00:05:33
Or you could treat it
continuously and say, well,

81
00:05:33 --> 00:05:37
we're just going to treat blood
as a fluid, not made up of

82
00:05:37 --> 00:05:41
discrete components, and write
some equations to model how

83
00:05:41 --> 00:05:45
that fluid goes through
and then simulate that.

84
00:05:45 --> 00:05:50
In this course, we're going
to be focusing mostly on

85
00:05:50 --> 00:05:56
discrete simulations.


86
00:05:56 --> 00:05:59
Now if we think about the
random walk we looked at,

87
00:05:59 --> 00:06:10
indeed it was stochastic,
dynamic, and discrete.

88
00:06:10 --> 00:06:14
The random walk was an
example of what's called

89
00:06:14 --> 00:06:21
a Monte Carlo simulation.


90
00:06:21 --> 00:06:28
This term was coined there.


91
00:06:28 --> 00:06:32
Anyone know what that is?


92
00:06:32 --> 00:06:34
Anyone want to guess?


93
00:06:34 --> 00:06:39
It's the casino, in
Monaco, in Monte Carlo.

94
00:06:39 --> 00:06:43
It was at one time, before
there was even a Las Vegas,

95
00:06:43 --> 00:06:47
the most famous casino
in the world certainly.

96
00:06:47 --> 00:06:50
Still one of the more opulent
ones as you can see.

97
00:06:50 --> 00:06:53
And unlike Las Vegas, it's
real opulence, as opposed

98
00:06:53 --> 00:06:57
to faux opulence.


99
00:06:57 --> 00:07:01
And this term Monte Carlo
simulation, was coined by Ulam

100
00:07:01 --> 00:07:07
and Metropolis, two
mathematicians, back in 1949,

101
00:07:07 --> 00:07:10
in reference to the fact that
at Monte Carlos, people bet on

102
00:07:10 --> 00:07:15
roulette wheels, and cards on a
table, games of chance, where

103
00:07:15 --> 00:07:19
there was randomness, and
things are discrete,

104
00:07:19 --> 00:07:20
in some sense.


105
00:07:20 --> 00:07:23
And they decided, well, this
is just like gambling, and

106
00:07:23 --> 00:07:28
so they called them Monte
Carlos simulations.

107
00:07:28 --> 00:07:33
What Is it that makes
this approach work?

108
00:07:33 --> 00:07:40
And, in some sense, I won't go
into a lot of the math, but I

109
00:07:40 --> 00:07:44
would like to get some
concepts across.

110
00:07:44 --> 00:07:46
This is an application
of what are called

111
00:07:46 --> 00:07:50
inferential statistics.


112
00:07:50 --> 00:07:55
You have some sample size, some
number of points, and from

113
00:07:55 --> 00:08:00
that you try to infer
something more general.

114
00:08:00 --> 00:08:06
We always depend upon one
property when we do this.

115
00:08:06 --> 00:08:19
And that property is that, a
randomly chosen sample tends to

116
00:08:19 --> 00:08:44
exhibit the same properties as
the population from

117
00:08:44 --> 00:08:55
which it is drawn.


118
00:08:55 --> 00:08:59
So you take a population of
anything, red balls and black

119
00:08:59 --> 00:09:07
balls, or students, or steps,
and at random draw some sample,

120
00:09:07 --> 00:09:12
and you assume that that sample
has properties similar to

121
00:09:12 --> 00:09:17
the entire population.


122
00:09:17 --> 00:09:23
So if I were to go around this
room and choose some random

123
00:09:23 --> 00:09:32
sample of you guys and write
down your hair color, we would

124
00:09:32 --> 00:09:35
be assuming that the fraction
of you with blonde hair in that

125
00:09:35 --> 00:09:39
sample would be the same as the
fraction of you with blonde

126
00:09:39 --> 00:09:42
hair in the whole class.


127
00:09:42 --> 00:09:44
That's kind of what this means.


128
00:09:44 --> 00:09:50
And the same would be true of
black hair, auburn hair, etc.

129
00:09:50 --> 00:09:57
So consider, for example,
flipping a coin.

130
00:09:57 --> 00:10:06
And if I were to flip it some
number of times, say 100 times,

131
00:10:06 --> 00:10:11
you might be able to, from the
proportion of heads and tails,

132
00:10:11 --> 00:10:15
be able to infer whether
or not the coin was fair.

133
00:10:15 --> 00:10:17
That is to say, half the times
it would be heads, in half the

134
00:10:17 --> 00:10:21
times it would be that tails,
or whether it was unfair, that

135
00:10:21 --> 00:10:24
it was somehow weighted, so
that heads would come

136
00:10:24 --> 00:10:26
up more than tails.


137
00:10:26 --> 00:10:28
And you might say if we did
this 100 times and looked at

138
00:10:28 --> 00:10:33
the results, then we could make
a decision about what would

139
00:10:33 --> 00:10:37
happen in general when
we looked at the coin.

140
00:10:37 --> 00:10:45
So let's look in an
example of doing that.

141
00:10:45 --> 00:10:50
So I wrote a little program,
it's on your handout,

142
00:10:50 --> 00:10:54
to flip a coin.


143
00:10:54 --> 00:10:56
So this looks like
the simulations we

144
00:10:56 --> 00:10:58
looked at before.


145
00:10:58 --> 00:11:02
I've got flip trials, which
says that the number

146
00:11:02 --> 00:11:07
of heads and tails is
0 for i in x range.

147
00:11:07 --> 00:11:09
What is x range?


148
00:11:09 --> 00:11:13
So normally you would have
written, for i in range

149
00:11:13 --> 00:11:16
zero to num flips.


150
00:11:16 --> 00:11:21
What range does, is it creates
a list, in this case from 0 to

151
00:11:21 --> 00:11:27
99 and goes through the
list of one at a time.

152
00:11:27 --> 00:11:34
That's fine, but supposed
num flips were a billion.

153
00:11:34 --> 00:11:39
Well, range would create a list
with a billion numbers in it.

154
00:11:39 --> 00:11:42
Which would take a lot of
space in the computer.

155
00:11:42 --> 00:11:44
And it's kind of wasted.


156
00:11:44 --> 00:11:50
What x range says is, don't
bother creating the list just

157
00:11:50 --> 00:11:54
go through the, in this case,
the numbers one at a time.

158
00:11:54 --> 00:11:58
So it's much more
efficient than range.

159
00:11:58 --> 00:12:04
It will behave the same way as
far as the answers you get, but

160
00:12:04 --> 00:12:06
it doesn't use as much space.


161
00:12:06 --> 00:12:09
And since some of the
simulations we'll be doing will

162
00:12:09 --> 00:12:13
have lots of trials, or lots of
flips, it's worth the

163
00:12:13 --> 00:12:15
trouble to use x range
instead of range.

164
00:12:15 --> 00:12:19
Yeah?


165
00:12:19 --> 00:12:23
Pardon?


166
00:12:23 --> 00:12:25
STUDENT: Like, why would
we ever use range

167
00:12:25 --> 00:12:26
instead of x range?


168
00:12:26 --> 00:12:28
PROFESSOR: No good reason, when
dealing with numbers, unless

169
00:12:28 --> 00:12:32
you wanted to do something
different with the list.

170
00:12:32 --> 00:12:39
But, there's no good reason.


171
00:12:39 --> 00:12:41
The right answer for
the purposes of today

172
00:12:41 --> 00:12:43
is, no good reason.


173
00:12:43 --> 00:12:47
I typically use x range all the
time if I'm thinking about it.

174
00:12:47 --> 00:12:51
It was just something that
didn't seem worth introducing

175
00:12:51 --> 00:12:53
earlier in this semester.


176
00:12:53 --> 00:12:55
But good question.


177
00:12:55 --> 00:13:03
Certainly deserving
of a piece of candy.

178
00:13:03 --> 00:13:06
All right, so for i in x
range, coin is equal some

179
00:13:06 --> 00:13:08
random integer 0 or 1.


180
00:13:08 --> 00:13:13
If coin is equal to 0
then heads, else tails.

181
00:13:13 --> 00:13:16
Well, that's pretty easy.


182
00:13:16 --> 00:13:19
And then all I'm going to do
here is go through and flip it

183
00:13:19 --> 00:13:27
a bunch of times, and we'll get
some answer, and do some plots.

184
00:13:27 --> 00:13:31
So let's look at an example.


185
00:13:31 --> 00:13:55
We'll try -- we'll flip 100
coins, we'll do 100 trials

186
00:13:55 --> 00:13:59
and see what we get.


187
00:13:59 --> 00:14:01
Error in multi-line statement.


188
00:14:01 --> 00:14:05
All right, what have
I done wrong here?

189
00:14:05 --> 00:14:08
Obviously did something by
accident, edited something

190
00:14:08 --> 00:14:12
I did not intend edit.


191
00:14:12 --> 00:14:15
Anyone spot what I did wrong?


192
00:14:15 --> 00:14:18
Pardon?


193
00:14:18 --> 00:14:21
The parentheses.


194
00:14:21 --> 00:14:22
I typed where I didn't intend.


195
00:14:22 --> 00:14:24
Which line?


196
00:14:24 --> 00:14:29
Down at the bottom?


197
00:14:29 --> 00:14:35
Obviously my, here,
yes, I deleted that.

198
00:14:35 --> 00:14:46
Thank you.


199
00:14:46 --> 00:14:52
All right, so we have a
couple of figures here.

200
00:14:52 --> 00:14:59
Figure one, I'm
showing a histogram.

201
00:14:59 --> 00:15:05
The number of trials on the
y-axis and the difference

202
00:15:05 --> 00:15:08
between heads and tails ,
do I have more of one than

203
00:15:08 --> 00:15:10
the other on the x-axis.


204
00:15:10 --> 00:15:14
And so we what we could see out
of my 100 trials, somewhere

205
00:15:14 --> 00:15:21
around 22 of them came out
the same, close to the same.

206
00:15:21 --> 00:15:25
But way over here we've
got some funny ones.

207
00:15:25 --> 00:15:28
100 and there was a
difference of 25.

208
00:15:28 --> 00:15:31
Pretty big difference.


209
00:15:31 --> 00:15:35
Another way to look at the same
data, and I'm doing this just

210
00:15:35 --> 00:15:37
to show that there are
different ways of looking at

211
00:15:37 --> 00:15:46
data, is here, what I've
plotted is each trial,

212
00:15:46 --> 00:15:49
the percent difference.


213
00:15:49 --> 00:15:51
So out of 100 flips.


214
00:15:51 --> 00:15:54
And this is normalizing it,
because if I flip a million

215
00:15:54 --> 00:15:59
coins, I might expect the
difference to be pretty big in

216
00:15:59 --> 00:16:01
absolute terms, but maybe very
small as a percentage

217
00:16:01 --> 00:16:04
of a million.


218
00:16:04 --> 00:16:08
And so here, we can again see
that as these stochastic kinds

219
00:16:08 --> 00:16:12
of things, there's a pretty
big difference, right?

220
00:16:12 --> 00:16:17
We've got one where it
was over 25 percent, and

221
00:16:17 --> 00:16:20
several where it's zero.


222
00:16:20 --> 00:16:24
So the point here, we can see
from this graph, that if I'd

223
00:16:24 --> 00:16:28
done only one trial and just
assumed that was the answer as

224
00:16:28 --> 00:16:31
to whether my coin was weighted
or not, I could really

225
00:16:31 --> 00:16:35
have fooled myself.


226
00:16:35 --> 00:16:40
So the the main point is that
you need to be careful when

227
00:16:40 --> 00:16:44
you're doing these
kinds of things.

228
00:16:44 --> 00:16:48
And this green line
here is the mean.

229
00:16:48 --> 00:16:54
So it says on average, the
difference was seven precent.

230
00:16:54 --> 00:17:14
Well suppose, maybe, instead
of, flipping 100, I

231
00:17:14 --> 00:17:42
were to flip 1,000.


232
00:17:42 --> 00:17:44
Well, doesn't seem to
want to notice it.

233
00:17:44 --> 00:17:49
One more try and then I'll just
restart it, which is always the

234
00:17:49 --> 00:18:07
safest thing as we've
discussed before.

235
00:18:07 --> 00:18:14
Well, we won't panic.


236
00:18:14 --> 00:18:20
Sometimes this helps.


237
00:18:20 --> 00:18:26
If not, here we go.


238
00:18:26 --> 00:18:29
So let's say we wanted
to flip 1,000 coins.

239
00:18:29 --> 00:18:33
So now what do we think?


240
00:18:33 --> 00:18:36
Is the difference going to
be bigger or smaller than

241
00:18:36 --> 00:18:37
when we flipped 100?


242
00:18:37 --> 00:18:42
Is the average difference
between heads and tails

243
00:18:42 --> 00:18:48
bigger or smaller with 1,000
flips than with 100 flips?

244
00:18:48 --> 00:18:51
Well, the percentage will be
smaller, but in absolute

245
00:18:51 --> 00:18:55
terms, it's probably going
to be bigger, right?

246
00:18:55 --> 00:19:01
Because I've got more
chances to stray.

247
00:19:01 --> 00:19:17
But we'll find out.


248
00:19:17 --> 00:19:22
So here we see that the mean
difference is somewhere in the

249
00:19:22 --> 00:19:26
twenties, which was much higher
than the mean difference

250
00:19:26 --> 00:19:28
for 100 flips.


251
00:19:28 --> 00:19:31
On the other hand, if we
look at the percentage,

252
00:19:31 --> 00:19:32
we see it's much lower.


253
00:19:32 --> 00:19:34
Instead of seven percent,
it's around two and a

254
00:19:34 --> 00:19:37
half percent in the main.


255
00:19:37 --> 00:19:40
There's something else
interesting to observe in

256
00:19:40 --> 00:19:44
figure two, relative to when
we looked at with 100 flips.

257
00:19:44 --> 00:19:47
What else is pretty interesting
about the difference between

258
00:19:47 --> 00:19:52
these two figures, if you
can remember the other one?

259
00:19:52 --> 00:19:52
Yeah?


260
00:19:52 --> 00:19:54
STUDENT: There are no zeros?


261
00:19:54 --> 00:19:57
PROFESSOR: There are no zeros.


262
00:19:57 --> 00:20:04
That's right, as it happens
there were no zeros.

263
00:20:04 --> 00:20:07
Not so surprising that
it didn't ever come

264
00:20:07 --> 00:20:10
out exactly 500, 500.


265
00:20:10 --> 00:20:14
What else?


266
00:20:14 --> 00:20:16
What was the biggest
difference, percentage-wise,

267
00:20:16 --> 00:20:19
we saw last time?


268
00:20:19 --> 00:20:20
Over 25.


269
00:20:20 --> 00:20:24
So notice how much narrower
the range is here.

270
00:20:24 --> 00:20:29
Instead of ranging from 2 to 25
or something like that, it

271
00:20:29 --> 00:20:35
ranges from 0 to 7, or
maybe 7 and a little.

272
00:20:35 --> 00:20:41
So, by flipping more coins,
the experiment becomes

273
00:20:41 --> 00:20:43
more reproduce-able.


274
00:20:43 --> 00:20:50
I'm looks like the same because
of scaling, but in fact the

275
00:20:50 --> 00:20:52
range is much narrower.


276
00:20:52 --> 00:20:57
Each experiment tends to give
an answer closer to all

277
00:20:57 --> 00:21:01
the other experiments.


278
00:21:01 --> 00:21:03
That's a good thing.


279
00:21:03 --> 00:21:08
It should give you confidence
that the answers are getting

280
00:21:08 --> 00:21:10
pretty close to right.


281
00:21:10 --> 00:21:13
That they're not bouncing
all over the place.

282
00:21:13 --> 00:21:17
And if I were to flip a million
coins, we would find the

283
00:21:17 --> 00:21:22
range would get very tight.


284
00:21:22 --> 00:21:24
So notice that even though
there's similar information in

285
00:21:24 --> 00:21:30
the histogram and the plot,
different things leap out

286
00:21:30 --> 00:21:36
at you, as you look at it.


287
00:21:36 --> 00:21:40
All right, we could ask a
lot of other interesting

288
00:21:40 --> 00:21:46
questions about coins here.


289
00:21:46 --> 00:21:48
But, we'll come back to this
in a minute and look at

290
00:21:48 --> 00:21:52
some other questions.


291
00:21:52 --> 00:21:56
I want to talk again a
little bit more generally.

292
00:21:56 --> 00:21:59
It's kind of easy to think
about running a simulation

293
00:21:59 --> 00:22:01
to predict the future.


294
00:22:01 --> 00:22:06
So in some sense, we look
at this, and this predicts

295
00:22:06 --> 00:22:10
what might happen if I
flipped 1,000 coins.

296
00:22:10 --> 00:22:16
That the most likely event
would be that I'd have

297
00:22:16 --> 00:22:24
something under 10 in the
difference between heads and

298
00:22:24 --> 00:22:28
tails, but that it's not
terribly unlikely that I

299
00:22:28 --> 00:22:34
might have close to
70 as a difference.

300
00:22:34 --> 00:22:37
And if I ran more than 100
trials I'd see more, but

301
00:22:37 --> 00:22:42
this helps me predict
what might happen.

302
00:22:42 --> 00:22:46
Now we don't always use
simulations to predict

303
00:22:46 --> 00:22:47
what might happen.


304
00:22:47 --> 00:22:52
We sometimes actually use
simulations to understand the

305
00:22:52 --> 00:22:54
current state of the world.


306
00:22:54 --> 00:22:59
So for example, if I told you
that we are going to flip three

307
00:22:59 --> 00:23:07
coins, and I wanted you to
predict the probability that

308
00:23:07 --> 00:23:10
all three would be either
heads, or all three

309
00:23:10 --> 00:23:12
would be tails.


310
00:23:12 --> 00:23:14
Well, if you'd studied any
probability, you could

311
00:23:14 --> 00:23:15
know how to do that.


312
00:23:15 --> 00:23:18
If you hadn't studied
probability, you would say,

313
00:23:18 --> 00:23:22
well, that's OK, we have a
simulation right here.

314
00:23:22 --> 00:23:27
Let's just do it.


315
00:23:27 --> 00:23:45
Here we go again.


316
00:23:45 --> 00:23:46
And so let's try it.


317
00:23:46 --> 00:24:06
Let's flip three coins, and
let's do it 4,000 times here.

318
00:24:06 --> 00:24:07
Well, that's kind
of hard to read.

319
00:24:07 --> 00:24:09
It's pretty dense.


320
00:24:09 --> 00:24:19
But we can see that
the mean here is 50.

321
00:24:19 --> 00:24:24
And, this is a little
easier to read.

322
00:24:24 --> 00:24:31
This tells us that, how many
times will the difference,

323
00:24:31 --> 00:24:38
right, be zero 3,000
out of 4,000.

324
00:24:38 --> 00:24:39
Is that right?


325
00:24:39 --> 00:24:41
What do you think?


326
00:24:41 --> 00:24:42
Do you believe this?


327
00:24:42 --> 00:24:46
Have I done the right thing?
three coins, 4,000 flips,

328
00:24:46 --> 00:24:49
how often should they all
be heads, or how often

329
00:24:49 --> 00:24:54
should they all be tails?


330
00:24:54 --> 00:24:54
What does this tell us?


331
00:24:54 --> 00:25:01
It tells us one-fourth of the
time they'll all be-- the

332
00:25:01 --> 00:25:03
difference between, wait a
minute, how can the difference

333
00:25:03 --> 00:25:09
between -- something's
wrong with my code, right?

334
00:25:09 --> 00:25:11
Because I only have
two possible values.

335
00:25:11 --> 00:25:17
I hadn't expected this.


336
00:25:17 --> 00:25:20
I obviously messed
something up.

337
00:25:20 --> 00:25:21
Pardon?


338
00:25:21 --> 00:25:22
STUDENT: It's right.


339
00:25:22 --> 00:25:24
PROFESSOR: It's right, because?


340
00:25:24 --> 00:25:28
STUDENT: Because you had an
odd number of flips, and

341
00:25:28 --> 00:25:29
when you split them --


342
00:25:29 --> 00:25:29
PROFESSOR: Pardon?


343
00:25:29 --> 00:25:29
STUDENT: When you


344
00:25:29 --> 00:25:32
split an odd number --


345
00:25:32 --> 00:25:35
PROFESSOR: Exactly.


346
00:25:35 --> 00:25:36
So it is correct.


347
00:25:36 --> 00:25:37
And it gives us what we want.


348
00:25:37 --> 00:25:41
But now, let's think about
a different situation.

349
00:25:41 --> 00:25:42
Anybody got a coin here?


350
00:25:42 --> 00:25:46
Anyone give me three coins?


351
00:25:46 --> 00:25:55
I can trust somebody, I hope.


352
00:25:55 --> 00:25:56
What a cheap -- anybody
got silver dollars,

353
00:25:56 --> 00:25:59
would be preferable?


354
00:25:59 --> 00:26:01
All right, look at this.


355
00:26:01 --> 00:26:06
She's very carefully
given me three pennies.

356
00:26:06 --> 00:26:09
She had big, big money in that
purse, too, but she didn't

357
00:26:09 --> 00:26:11
want me to have it.


358
00:26:11 --> 00:26:15
All right, so I'm going to take
these three pennies, jiggle

359
00:26:15 --> 00:26:19
them up, and now ask you,
what's the probability that

360
00:26:19 --> 00:26:24
all three of them are heads?


361
00:26:24 --> 00:26:26
Anyone want to tell me?


362
00:26:26 --> 00:26:30
It's either 0 or 1, right?


363
00:26:30 --> 00:26:32
And I can actually look
at you and tell you

364
00:26:32 --> 00:26:33
exactly which it is.


365
00:26:33 --> 00:26:38
And you can't see which it is.


366
00:26:38 --> 00:26:43
So, how should you think about
what the probability it?

367
00:26:43 --> 00:26:48
Well, you might as well assume
that it's whatever this

368
00:26:48 --> 00:26:52
graph tells you it is.


369
00:26:52 --> 00:26:57
Because the fact that you don't
have access to the information,

370
00:26:57 --> 00:27:00
means that you really might as
well treat the present

371
00:27:00 --> 00:27:02
as if it's the future.


372
00:27:02 --> 00:27:04
That it's unknown.


373
00:27:04 --> 00:27:08
And so in fact we frequently,
when there's data out there

374
00:27:08 --> 00:27:13
that we don't have access
to, we use simulations and

375
00:27:13 --> 00:27:17
probabilities to estimate, make
our best guess, about the

376
00:27:17 --> 00:27:20
current state of the world.


377
00:27:20 --> 00:27:24
And so, in fact, guessing the
value of the current state, is

378
00:27:24 --> 00:27:27
really no different from
predicting the value of a

379
00:27:27 --> 00:27:34
future state when you don't
have the information.

380
00:27:34 --> 00:27:40
In general, all right, now,
just to show that your

381
00:27:40 --> 00:27:52
precautions were unnecessary.


382
00:27:52 --> 00:27:55
Where was I?


383
00:27:55 --> 00:27:57
Right.


384
00:27:57 --> 00:28:05
In general, when we're trying
to predict the future, or in

385
00:28:05 --> 00:28:09
this case, guess the present,
we have to use information we

386
00:28:09 --> 00:28:17
already have to make our
prediction or our best guess.

387
00:28:17 --> 00:28:21
So to do that, we have to
always ask the question, is

388
00:28:21 --> 00:28:28
past behavior a good prediction
of future behavior?

389
00:28:28 --> 00:28:32
So if I flip a coin 1,000 times
and count up the heads and

390
00:28:32 --> 00:28:34
tails, is that a good
prediction what will

391
00:28:34 --> 00:28:39
happen the next time?


392
00:28:39 --> 00:28:43
This is a step people
often omit, in doing

393
00:28:43 --> 00:28:46
these predictions.


394
00:28:46 --> 00:28:49
See the recent meltdown
of the financial system.

395
00:28:49 --> 00:28:52
Where people had lots of
stochastic simulations

396
00:28:52 --> 00:28:55
predicting what the market
would do, and they were all

397
00:28:55 --> 00:28:58
wrong, because they were all
based upon assuming samples

398
00:28:58 --> 00:29:02
drawn from the past would
predict the future.

399
00:29:02 --> 00:29:06
So, as we build these models,
that's the question you

400
00:29:06 --> 00:29:08
always have to ask yourself.


401
00:29:08 --> 00:29:14
Is, in some sense, this true?


402
00:29:14 --> 00:29:17
Because usually what we're
doing is, we're choosing a

403
00:29:17 --> 00:29:24
random sample from the past and
hoping it predicts the future.

404
00:29:24 --> 00:29:27
And that is to say, is
the population we have

405
00:29:27 --> 00:29:31
available the same has
the one in the future.

406
00:29:31 --> 00:29:34
So it's easy to see how one
might use these kinds of

407
00:29:34 --> 00:29:38
simulations to figure
out things that are

408
00:29:38 --> 00:29:41
inherently stochastic.


409
00:29:41 --> 00:29:47
So for example, to
predict a poker hand.

410
00:29:47 --> 00:29:49
What's the probability of my
getting a full house when I

411
00:29:49 --> 00:29:53
draw this card from the deck?


412
00:29:53 --> 00:29:55
To predict the probability of
coming up with a particular

413
00:29:55 --> 00:29:57
kind of poker hand.


414
00:29:57 --> 00:30:02
Is a full house more
probable than a straight?

415
00:30:02 --> 00:30:03
Or not?


416
00:30:03 --> 00:30:06
Well, you can deal out lots of
cards, and count them up, just

417
00:30:06 --> 00:30:12
as Ulam suggested
for Solitaire.

418
00:30:12 --> 00:30:14
And that's often what we do.


419
00:30:14 --> 00:30:20
Interestingly enough though, we
can use randomized techniques

420
00:30:20 --> 00:30:26
to get solutions to problems
that are not inherently

421
00:30:26 --> 00:30:29
stochastic.


422
00:30:29 --> 00:30:31
And that's what I
want to do now.

423
00:30:31 --> 00:30:37
So, consider for example, pi.


424
00:30:37 --> 00:30:41
Many of you have
probably heard of this.

425
00:30:41 --> 00:30:45
For thousands of years,
literally, people have known

426
00:30:45 --> 00:30:51
that there is a constant, pi,
associated with circles such

427
00:30:51 --> 00:30:59
that pi times the radius
squared equals the area.

428
00:30:59 --> 00:31:03
And they've known that pi
times the diameter is equal

429
00:31:03 --> 00:31:08
to the circumference.


430
00:31:08 --> 00:31:13
So, back in the days of the
Egyptian pharaohs, it was known

431
00:31:13 --> 00:31:15
that such a constant existed.


432
00:31:15 --> 00:31:20
In fact, it didn't acquire the
name pi until the 18th century.

433
00:31:20 --> 00:31:22
And so they called it
other things, but

434
00:31:22 --> 00:31:26
they knew it existed.


435
00:31:26 --> 00:31:29
And for thousands of years,
people have speculated

436
00:31:29 --> 00:31:32
on what it's value was.


437
00:31:32 --> 00:31:42
Sometime around 1650 BC, the
Egyptians said that pi was

438
00:31:42 --> 00:31:46
3.16, something called
the Rhind Papyrus,

439
00:31:46 --> 00:31:52
something they found.


440
00:31:52 --> 00:32:00
Many years later, about 1,000
years later, the Bible

441
00:32:00 --> 00:32:04
said pi was three.


442
00:32:04 --> 00:32:11
And I quote, this is describing
the specifications for the

443
00:32:11 --> 00:32:16
Great Temple of Solomon. "He
made a molten sea of 10 cubits

444
00:32:16 --> 00:32:20
from brim to brim, round in
compass, and 5 cubit the height

445
00:32:20 --> 00:32:24
thereof, and a line of 30
cubits did compass it round

446
00:32:24 --> 00:32:30
about." So, all right, so what
we've got here is, we've got

447
00:32:30 --> 00:32:34
everything we need to plug into
these equations and solve for

448
00:32:34 --> 00:32:37
pi, and it comes out three.


449
00:32:37 --> 00:32:42
And it does this in more than
one place in the Bible.

450
00:32:42 --> 00:32:46
I will not comment on the
theological implications

451
00:32:46 --> 00:32:49
of this assertion.


452
00:32:49 --> 00:32:52
Sarah Palin might.


453
00:32:52 --> 00:32:55
And Mike Huckabee
certainly would.

454
00:32:55 --> 00:33:00
The first theoretical
calculation of pi was carried

455
00:33:00 --> 00:33:05
out by Archimedes, a great
Greek mathematician from

456
00:33:05 --> 00:33:11
Syracuse, that was about
somewhere around 250 BC.

457
00:33:11 --> 00:33:19
And he said that pi was
somewhere between 223 divided

458
00:33:19 --> 00:33:31
by 71, and 22 divided by 7.


459
00:33:31 --> 00:33:34
This was amazingly profound.


460
00:33:34 --> 00:33:39
He knew he didn't know what the
answer was, but he had a way to

461
00:33:39 --> 00:33:42
give an upper and a lower
bound, and say it was somewhere

462
00:33:42 --> 00:33:45
between these two values.


463
00:33:45 --> 00:33:50
And in fact if you calculate
it, the average of those

464
00:33:50 --> 00:33:56
two values is 3.1418.


465
00:33:56 --> 00:33:58
Not bad for the time.


466
00:33:58 --> 00:34:01
This was not by measurement, he
actually had a very interesting

467
00:34:01 --> 00:34:04
way of calculating it.


468
00:34:04 --> 00:34:09
All right, so this is where it
stood, for years and years,

469
00:34:09 --> 00:34:12
because of course people forgot
the Rhind Papyrus, and they

470
00:34:12 --> 00:34:15
forgot Archimedes, and they
believed the Bible, and so

471
00:34:15 --> 00:34:19
three was used for a long time.


472
00:34:19 --> 00:34:23
People sort of knew it
wasn't right, but still.

473
00:34:23 --> 00:34:33
Then quite interestingly,
Buffon and Laplace, two great

474
00:34:33 --> 00:34:37
French mathematicians, actually
people had better estimates

475
00:34:37 --> 00:34:41
using Archimedes' methods long
before they came along,

476
00:34:41 --> 00:34:45
proposed a way to do it
using a simulation.

477
00:34:45 --> 00:34:52
Now, since Laplace lived
between 1749 and 1827, it was

478
00:34:52 --> 00:34:56
not a computer simulation.


479
00:34:56 --> 00:34:59
So I'm going to show you,
basically, the way that he

480
00:34:59 --> 00:35:08
proposed to do it. the basic
idea was you take a square,

481
00:35:08 --> 00:35:12
assume that's a square, and
you inscribe in it a

482
00:35:12 --> 00:35:16
quarter of a circle.


483
00:35:16 --> 00:35:23
So here, you have the
radius of the square r.

484
00:35:23 --> 00:35:31
And then you get some person
to, he used needles, but

485
00:35:31 --> 00:35:37
I'm going to use darts, to
throw darts at the shape.

486
00:35:37 --> 00:35:44
And some number of the darts
will land in the circle part,

487
00:35:44 --> 00:35:48
and some number of the darts
will land out here, in the

488
00:35:48 --> 00:35:55
part of the square that's
not inscribed by the circle.

489
00:35:55 --> 00:36:02
And then we can look at the
ratio of the darts in the

490
00:36:02 --> 00:36:11
shaded area divided by the
total number of darts

491
00:36:11 --> 00:36:16
in the square.


492
00:36:16 --> 00:36:26
And that's equal to the
shaded area divided by

493
00:36:26 --> 00:36:31
the area of the square.


494
00:36:31 --> 00:36:34
The notion being, if they're
landing at random in these

495
00:36:34 --> 00:36:41
places, the proportion here
and not here will depend

496
00:36:41 --> 00:36:44
upon the relative areas.


497
00:36:44 --> 00:36:45
And that certainly makes sense.


498
00:36:45 --> 00:36:49
If this were half the area of
the square, then you'd expect

499
00:36:49 --> 00:36:55
half the darts to land in here.


500
00:36:55 --> 00:36:58
And then as you can see in your
handout, a little simple

501
00:36:58 --> 00:37:09
algebra can take this, plus pi
r squared equals the area, you

502
00:37:09 --> 00:37:16
can solve for pi, and you can
get that pi is equal to 4, and

503
00:37:16 --> 00:37:19
I'll write it, h, where
h is the hit ratio, the

504
00:37:19 --> 00:37:22
number falling in here.


505
00:37:22 --> 00:37:27
So people sort of see why that
should work intuitively?

506
00:37:27 --> 00:37:31
And that it's a very clever
idea to use randomness to

507
00:37:31 --> 00:37:34
find a value that there's
nothing random about.

508
00:37:34 --> 00:37:36
So we can now do
the experiment.

509
00:37:36 --> 00:37:42
I need volunteers
to throw darts.

510
00:37:42 --> 00:37:44
Come on.


511
00:37:44 --> 00:37:48
Come on up.


512
00:37:48 --> 00:37:50
I need more volunteers.


513
00:37:50 --> 00:37:51
I have a lot of darts.


514
00:37:51 --> 00:37:56
Anybody else?


515
00:37:56 --> 00:37:58
Anybody?


516
00:37:58 --> 00:38:00
All right, then since
you're all in the front

517
00:38:00 --> 00:38:07
row, you get stuck.


518
00:38:07 --> 00:38:11
So now we'll try it.


519
00:38:11 --> 00:38:14
And you guys, we'll see how
many of you hit in the circle,

520
00:38:14 --> 00:38:20
and how many of you hit there.


521
00:38:20 --> 00:38:24
Go ahead, on the count
of 3, everybody throw.

522
00:38:24 --> 00:38:28
1, 2, 3.


523
00:38:28 --> 00:38:30
Ohh!


524
00:38:30 --> 00:38:34
He did that on purpose.


525
00:38:34 --> 00:38:36
You'll notice Professor Grimson
isn't here today, and that's

526
00:38:36 --> 00:38:41
because I told him he was going
to have to hold the dart board.

527
00:38:41 --> 00:38:47
Well, what we see here is,
we ignore the ones that

528
00:38:47 --> 00:38:49
missed all together.


529
00:38:49 --> 00:38:52
And we'll see that, truly,
I'm assuming these

530
00:38:52 --> 00:38:54
are random throws.


531
00:38:54 --> 00:38:55
We have one here and two


532
00:38:55 --> 00:38:55
here.


533
00:38:55 --> 00:39:01
Well, your eyes will tell
you that's the wrong ratio.

534
00:39:01 --> 00:39:04
Which suggests that having
students throw darts is not the

535
00:39:04 --> 00:39:07
best way to solve this problem.


536
00:39:07 --> 00:39:09
And so you will see in
your handout a computer

537
00:39:09 --> 00:39:14
simulation of it.


538
00:39:14 --> 00:39:20
So let's look at that.


539
00:39:20 --> 00:39:23
So this is find pi.


540
00:39:23 --> 00:39:26
So at the beginning of this
code, by the way, it's not on

541
00:39:26 --> 00:39:29
your handout, is some magic.


542
00:39:29 --> 00:39:32
I got tired of looking
at big numbers without

543
00:39:32 --> 00:39:34
commas separating the
thousands places.

544
00:39:34 --> 00:39:38
You've see me in other lectures
counting the number of zeros.

545
00:39:38 --> 00:39:43
What we have here is, that
just tells it I have to have

546
00:39:43 --> 00:39:47
two versions, one for the
Mac, and one for the PC.

547
00:39:47 --> 00:39:51
To set some variables that had
to write integers, things in

548
00:39:51 --> 00:39:54
general, and I'm saying here,
do it the way you would

549
00:39:54 --> 00:39:57
do it in the United
States in English.

550
00:39:57 --> 00:40:00
And UTF8 is just an
extended character code.

551
00:40:00 --> 00:40:03
Anyway, you don't need to learn
anything about this magic, but

552
00:40:03 --> 00:40:05
it's just a handy little way to
make the numbers

553
00:40:05 --> 00:40:09
easier to read.


554
00:40:09 --> 00:40:14
All right, so let's let's
try and look at it.

555
00:40:14 --> 00:40:18
There's not much
interesting to see here.

556
00:40:18 --> 00:40:21
I've done this little thing,
format ints, that uses this

557
00:40:21 --> 00:40:25
magic to say grouping equals
true, that means put a comma

558
00:40:25 --> 00:40:27
in the thousand places.


559
00:40:27 --> 00:40:29
But again, you can
ignore all that.

560
00:40:29 --> 00:40:37
The interesting part, is that
from Pylab I import star,

561
00:40:37 --> 00:40:39
import random in math.


562
00:40:39 --> 00:40:42
As some of you observed, the
order these imports matters.

563
00:40:42 --> 00:40:45
I think I sent out an email
yesterday explaining

564
00:40:45 --> 00:40:47
what was going on here.


565
00:40:47 --> 00:40:49
This was one of the things
that I knew, and probably

566
00:40:49 --> 00:40:51
should've mentioned.


567
00:40:51 --> 00:40:54
But since I knew it, I
thought everyone knew.

568
00:40:54 --> 00:40:55
Silly me.


569
00:40:55 --> 00:40:58
It was of course a
dumb thing to think.

570
00:40:58 --> 00:41:00
And then I'm going to
throw a bunch of darts.

571
00:41:00 --> 00:41:03
The other thing you'll notice
is, throw darts has a

572
00:41:03 --> 00:41:05
parameter called should plot.


573
00:41:05 --> 00:41:09
And that's because when I throw
a billion darts, I really don't

574
00:41:09 --> 00:41:13
want to try and take the time
to plot a billion points.

575
00:41:13 --> 00:41:18
So let's first look
at a little example.

576
00:41:18 --> 00:41:32
We'll try throwing
10,000 darts.

577
00:41:32 --> 00:41:38
And it gives me an estimated
value of pi of 3.16.

578
00:41:38 --> 00:41:44
And what we'll see here, is
that the number of darts

579
00:41:44 --> 00:41:46
thrown, the estimate
changes, right?

580
00:41:46 --> 00:41:52
When I threw one dart, the
estimate of pi was 4.

581
00:41:52 --> 00:41:56
I threw my second dart, it
dropped all the way to 3.

582
00:41:56 --> 00:41:59
And then it bounced around a
while, and then at the end, it

583
00:41:59 --> 00:42:03
starts to really stabilize
around the true value.

584
00:42:03 --> 00:42:06
You'll notice, by the way,
that what I've got here

585
00:42:06 --> 00:42:08
is a logarithmic x-axis.


586
00:42:08 --> 00:42:10
If you look at the code,
you'll see I've told

587
00:42:10 --> 00:42:13
it to be semi log x.


588
00:42:13 --> 00:42:16
And that's because I wanted you
to be able to see what was

589
00:42:16 --> 00:42:19
happening early on, where
it was fluctuating.

590
00:42:19 --> 00:42:21
But out here it's kind
of boring, because the

591
00:42:21 --> 00:42:23
fluctuations are so small.


592
00:42:23 --> 00:42:34
So that was a good
way to do it.

593
00:42:34 --> 00:42:37
All right now.


594
00:42:37 --> 00:42:38
Do I think I have
enough samples here?

595
00:42:38 --> 00:42:43
Well, I don't want you to cheat
and look at the estimate and

596
00:42:43 --> 00:42:45
say no, you don't, because
you know that's not

597
00:42:45 --> 00:42:46
the right answer.


598
00:42:46 --> 00:42:51
And, it's not even as
good as Archimedes did.

599
00:42:51 --> 00:42:55
But how could you sort of look
at the data, and get a sense

600
00:42:55 --> 00:42:58
that maybe this is not
the right answer?

601
00:42:58 --> 00:43:02
Well, even at the end, if we
look at it, it's still wiggling

602
00:43:02 --> 00:43:03
around a fair amount.


603
00:43:03 --> 00:43:12
We can zoom in.


604
00:43:12 --> 00:43:14
And it's bouncing
up and down here.

605
00:43:14 --> 00:43:20
I'm in a region, but it's sort
of makes us think that maybe

606
00:43:20 --> 00:43:22
it hasn't stabilized, right?


607
00:43:22 --> 00:43:27
You'd like it to not
be moving very much.

608
00:43:27 --> 00:43:31
Now, by the way, the other
thing we could've looked at,

609
00:43:31 --> 00:43:38
when we ran it, let's run
it again, probably get a

610
00:43:38 --> 00:43:43
different answer by the way.


611
00:43:43 --> 00:43:47
Yeah, notice the
different answer here.

612
00:43:47 --> 00:43:48
Turns out to be a better
answer, but it's just

613
00:43:48 --> 00:43:55
an accident, right?


614
00:43:55 --> 00:43:59
Notice in the beginning it
fluctuates wildly, and

615
00:43:59 --> 00:44:01
it fluctuates less
wildly at the end.

616
00:44:01 --> 00:44:04
Why is that?


617
00:44:04 --> 00:44:09
And don't just say because it's
close to right and it knows it.

618
00:44:09 --> 00:44:13
Why do the mathematics of this,
in some sense, tell us it

619
00:44:13 --> 00:44:16
has to fluctuate less
wildly at the end?

620
00:44:16 --> 00:44:17
Yes?


621
00:44:17 --> 00:44:22
STUDENT: [INAUDIBLE]


622
00:44:22 --> 00:44:27
PROFESSOR: Exactly,
exactly right.

623
00:44:27 --> 00:44:30
If I've only thrown two darts,
the third dart can have a big

624
00:44:30 --> 00:44:33
difference in the
average value.

625
00:44:33 --> 00:44:35
But if I've thrown a million
darts, the million and first

626
00:44:35 --> 00:44:38
can't matter very much.


627
00:44:38 --> 00:44:41
And what this tells me is, as
I want ever more digits of

628
00:44:41 --> 00:44:47
precision, I have to run a lot
more trials to get there.

629
00:44:47 --> 00:44:50
And that's often true, that
simulations can get you in the

630
00:44:50 --> 00:44:55
neighborhood quickly, but the
more precision you want, the

631
00:44:55 --> 00:45:00
number of steps grows
quite quickly.

632
00:45:00 --> 00:45:03
Now, the fact that I got such
different answers the two

633
00:45:03 --> 00:45:08
times I ran this suggests
strongly that I shouldn't

634
00:45:08 --> 00:45:10
believe either answer.


635
00:45:10 --> 00:45:13
Right?


636
00:45:13 --> 00:45:17
So we need to do
something else.

637
00:45:17 --> 00:45:30
So let's try something else.


638
00:45:30 --> 00:45:32
Let's try throwing a lot
more darts here, and

639
00:45:32 --> 00:45:42
see what we get.


640
00:45:42 --> 00:45:44
Now if you look at my code,
you'll see I'm printing

641
00:45:44 --> 00:45:47
intermediate values.


642
00:45:47 --> 00:45:50
Every million darts, I'm
printing the value.

643
00:45:50 --> 00:45:53
And I did that because the
first time I ran this on a big

644
00:45:53 --> 00:45:56
number, I was afraid I had
an infinite loop and my

645
00:45:56 --> 00:45:58
program was not working.


646
00:45:58 --> 00:46:00
So I just said, all right,
let's put a print statement

647
00:46:00 --> 00:46:06
in the loop, so I could see
that it's making progress.

648
00:46:06 --> 00:46:08
And then I decided it was just
kind of nice to look at it, to

649
00:46:08 --> 00:46:11
see what was going on here.


650
00:46:11 --> 00:46:15
So now you see that if I throw
10 million darts, I'm starting

651
00:46:15 --> 00:46:18
to get a much better estimate.


652
00:46:18 --> 00:46:22
You'll also see, as predicted,
that as I get further out, the

653
00:46:22 --> 00:46:26
value of the estimate changes
less and less with each million

654
00:46:26 --> 00:46:29
new darts, because it's a
smaller fraction of

655
00:46:29 --> 00:46:31
the total darts.


656
00:46:31 --> 00:46:36
But it's getting a lot better.


657
00:46:36 --> 00:46:40
Still not quite there.


658
00:46:40 --> 00:46:47
Let's just see what happens,
I can throw in another one.

659
00:46:47 --> 00:46:51
This is going to take
a little while.

660
00:46:51 --> 00:46:53
So I can talk while
it's running.

661
00:46:53 --> 00:47:06
Oops, what did I do here?


662
00:47:06 --> 00:47:12
So, it's going to keep on
going and going and going.

663
00:47:12 --> 00:47:15
And then if we were to run it
with this number of darts

664
00:47:15 --> 00:47:18
several times over, we would
discover that we got answers

665
00:47:18 --> 00:47:22
that were very, very similar.


666
00:47:22 --> 00:47:27
From that we can take comfort,
statistically, that we're

667
00:47:27 --> 00:47:30
really getting close to the
same answer every time, so

668
00:47:30 --> 00:47:34
we've probably thrown enough
darts to feel comfortable

669
00:47:34 --> 00:47:39
that we're doing what's
statistically the right thing.

670
00:47:39 --> 00:47:41
And that there maybe
isn't a lot of point in

671
00:47:41 --> 00:47:43
throwing more darts.


672
00:47:43 --> 00:47:48
Does that mean that we
have the right answer?

673
00:47:48 --> 00:47:51
No, not necessarily, and
that's what we're going

674
00:47:51 --> 00:47:53
to look at next week.


675
00:47:53 --> 00:47:54



